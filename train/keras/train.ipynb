{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"stack1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f48239c012fc4ad8a58ca90a5ab3e806":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7c441e19a13b4b5d81c0a7d9f64c7af6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_55aa5909f2d848268e99e9b821c4e6f3","IPY_MODEL_8b9e0d71bc8042cbb9de6dd2fb90128a"]}},"7c441e19a13b4b5d81c0a7d9f64c7af6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55aa5909f2d848268e99e9b821c4e6f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9689886f2d69404385a7c2d876f974a0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1499,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34653be3a9e94a5294079fdfcdd690a6"}},"8b9e0d71bc8042cbb9de6dd2fb90128a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_801e38e758d941a4bbde24edab0b4b78","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1499/1499 [00:02&lt;00:00, 575.13it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a52f3e84e79945d790f561a068d3acaa"}},"9689886f2d69404385a7c2d876f974a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"34653be3a9e94a5294079fdfcdd690a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"801e38e758d941a4bbde24edab0b4b78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a52f3e84e79945d790f561a068d3acaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c77e5325a8640198c001a22289c84be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9afc79aad0ad47e88c2afbece6af7288","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61a8f227b0304eda8b10f9244aa9c92c","IPY_MODEL_fce5de95bb6d4e158a91df7a99aec64b"]}},"9afc79aad0ad47e88c2afbece6af7288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61a8f227b0304eda8b10f9244aa9c92c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_94c41260a0384b108474bc02ff4f768c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":250,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":250,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f236bfd1d645408492b0186138200c26"}},"fce5de95bb6d4e158a91df7a99aec64b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_49dbb13752d04d35a55131c96dcd28fa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250/250 [00:00&lt;00:00, 520.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ba7938cdffd47a0b7ce774f3b7608db"}},"94c41260a0384b108474bc02ff4f768c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f236bfd1d645408492b0186138200c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49dbb13752d04d35a55131c96dcd28fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7ba7938cdffd47a0b7ce774f3b7608db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9fd81998d864a1aab87c47725b73db7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a7669038943841599db83180d03318b9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c9d5cb294feb4dd1b360cb8b7285df18","IPY_MODEL_9712828909e4494b9f50fdd9ad439360"]}},"a7669038943841599db83180d03318b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9d5cb294feb4dd1b360cb8b7285df18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_102e5da7bc474e33b07406ab0e8ec122","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1499,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_846d9ab6c2264272aed01665688e47e9"}},"9712828909e4494b9f50fdd9ad439360":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_48417965688a45f4864d3b374d41b955","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1499/1499 [00:03&lt;00:00, 383.52it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e03a30512ca14c64a275cc0adaf8eda2"}},"102e5da7bc474e33b07406ab0e8ec122":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"846d9ab6c2264272aed01665688e47e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"48417965688a45f4864d3b374d41b955":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e03a30512ca14c64a275cc0adaf8eda2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45b22000485d41b7b61ae04bf9768c3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0fc1180bbabb4209899f83758c649a31","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b8ed4911dae1484fb0de18efc8ce038e","IPY_MODEL_00cd6c0150e24827884b2e6c53611d3b"]}},"0fc1180bbabb4209899f83758c649a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8ed4911dae1484fb0de18efc8ce038e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a69129e0763b425c93d85ebc230dff28","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":250,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":250,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_095055b05707423199863b7438ef2c1d"}},"00cd6c0150e24827884b2e6c53611d3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7fcf641bb134438bb815f84100873cc4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250/250 [00:01&lt;00:00, 174.56it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8e4a2dbb45649c2a949bc81cd701adb"}},"a69129e0763b425c93d85ebc230dff28":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"095055b05707423199863b7438ef2c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7fcf641bb134438bb815f84100873cc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8e4a2dbb45649c2a949bc81cd701adb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e75b02dbafe48ef94ee4653d091985a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fc7ffe2db3b74905a17a3228f35733f4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_11451f38fc864a1fb943eca5e1cdfd09","IPY_MODEL_6232dab286874ef5a95753e6ea4ac985"]}},"fc7ffe2db3b74905a17a3228f35733f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11451f38fc864a1fb943eca5e1cdfd09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8750facf1df84c2d9ccc5e5b0d81f8e0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1499,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1499,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae14c777f4474d05af1c40179dbac0ad"}},"6232dab286874ef5a95753e6ea4ac985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea5306b25c3747c8859ebe26c2664a32","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1499/1499 [00:04&lt;00:00, 325.36it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2bf1c47e8e0b49c18529a5d6eedb6c8f"}},"8750facf1df84c2d9ccc5e5b0d81f8e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae14c777f4474d05af1c40179dbac0ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea5306b25c3747c8859ebe26c2664a32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2bf1c47e8e0b49c18529a5d6eedb6c8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ad89a4b509f488ea375937d2ae87848":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_44577303accd48b79af39be799e258d3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b54fce038ef7411fb6ca4905af5d1eaa","IPY_MODEL_00ee61ad46d346ce88f3ca2764c21ce0"]}},"44577303accd48b79af39be799e258d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b54fce038ef7411fb6ca4905af5d1eaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_44190e8a78664219b8a0e36671344420","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":250,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":250,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ad16099ff424b2aba63bcab07bad322"}},"00ee61ad46d346ce88f3ca2764c21ce0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05499b8d78f248a1a76ac16d0d0566ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250/250 [00:01&lt;00:00, 154.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1613c73333e545e2a4bd23fd4ad59a1a"}},"44190e8a78664219b8a0e36671344420":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3ad16099ff424b2aba63bcab07bad322":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05499b8d78f248a1a76ac16d0d0566ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1613c73333e545e2a4bd23fd4ad59a1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23a7fe9275394ba1953c8785a735310a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e08634baf311468bb497dc2ab0f661e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_47d6c9dcdfab42b1ae6bdecbd322e5a2","IPY_MODEL_40a5486a2c8d47b5b01a9a7f76e80825"]}},"e08634baf311468bb497dc2ab0f661e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47d6c9dcdfab42b1ae6bdecbd322e5a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_65efb968e29e4cb18c789098000676e1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b982aea6961745be8c6362b868231c74"}},"40a5486a2c8d47b5b01a9a7f76e80825":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b05ef2f3caf0498aa0f5b86b785b5d8d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1500/1500 [00:05&lt;00:00, 282.25it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e293f87493f41e68071f6180a5ea4ca"}},"65efb968e29e4cb18c789098000676e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b982aea6961745be8c6362b868231c74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b05ef2f3caf0498aa0f5b86b785b5d8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e293f87493f41e68071f6180a5ea4ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3721f923128498fae619fa1930c099d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ba052e17744346bbb74316d28ca6f793","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9596c5aa692f466aa1eaac5b9f416869","IPY_MODEL_5b7d20d7e512437398ef40d79aa12019"]}},"ba052e17744346bbb74316d28ca6f793":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9596c5aa692f466aa1eaac5b9f416869":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da9b26660d594009ba9c7eb601a3f768","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":250,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":250,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83e8846d634541b89ac4bf996ab393b5"}},"5b7d20d7e512437398ef40d79aa12019":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_636d6b422b2b4d0ebab1794cb17e8efe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250/250 [00:01&lt;00:00, 128.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac716f26ca404ff0b9a02d9dcb9adfbd"}},"da9b26660d594009ba9c7eb601a3f768":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"83e8846d634541b89ac4bf996ab393b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"636d6b422b2b4d0ebab1794cb17e8efe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ac716f26ca404ff0b9a02d9dcb9adfbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"3Qy5_CnuOgqz","colab_type":"code","outputId":"e7cf7e03-9c5c-4e01-def0-35c72275f65e","executionInfo":{"status":"ok","timestamp":1589734411590,"user_tz":-540,"elapsed":1039,"user":{"displayName":"Yasufumi Nakama","photoUrl":"","userId":"17486303986134302670"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kBxIMHlbvGsd","colab_type":"code","colab":{}},"source":["#!pip install tensorflow_addons"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I-Mo3IGPvMLC","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Conv1D, Input, Dense, Add, Multiply, concatenate, Reshape\n","from tensorflow.keras.layers import Embedding, Bidirectional\n","from tensorflow.compat.v1.keras.layers import CuDNNGRU\n","from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import losses, models, optimizers\n","import tensorflow_addons as tfa"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"k0lrq1HROaye","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Directory Settings\n","# =====================================================================================\n","DRIVE_PATH = './drive/My Drive/Colab Notebooks/Ion/'\n","ROOT = DRIVE_PATH+'input/liverpool-ion-switching/'\n","CLEAN_ROOT = DRIVE_PATH+'input/data-without-drift/'\n","OUTPUT_DIR = DRIVE_PATH+'stack1/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-FLqY3rOayh","colab_type":"code","colab":{}},"source":["class CFG:\n","    learning_rate=1e-3\n","    batch_size=16\n","    num_workers=4\n","    num_train_epochs=110\n","    weight_decay=0.01\n","    dropout=0.3\n","    emb_size=100\n","    hidden_size=164\n","    seq_len=5000\n","    total_cate_size=40\n","    seed=1225\n","    encoder='Wavenet_keras'\n","    target_size=11\n","    n_fold=4\n","    fold=[0, 1, 2, 3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulPo4ZTIvaaT","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Library\n","# =====================================================================================\n","import sys\n","import os\n","import gc\n","import time\n","from contextlib import contextmanager\n","from collections import Counter, defaultdict\n","\n","import numpy as np\n","import pandas as pd\n","import random\n","import json\n","\n","from sklearn.model_selection import StratifiedKFold, GroupKFold\n","from sklearn import preprocessing\n","\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# =====================================================================================\n","# Utils\n","# =====================================================================================\n","def get_logger(filename=OUTPUT_DIR+'log'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","logger = get_logger()\n","\n","\n","@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    logger.info(f'[{name}] start')\n","    yield\n","    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","\n","\n","# for tf\n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    tf.random.set_seed(seed)\n","\n","\n","def load_df(path, debug=False):\n","    # load df .csv or .pkl\n","    if path.split('.')[-1]=='csv':\n","        df = pd.read_csv(path)\n","        if debug:\n","            df = pd.read_csv(path, nrows=1000)\n","    elif path.split('.')[-1]=='pkl':\n","        df = pd.read_pickle(path)\n","    print(f\"{path} shape / {df.shape} \")\n","    return df\n","\n","\n","def make_stratified_group_k_folds(_df, _id, target, group, k, seed=42, save_path=OUTPUT_DIR+'folds.csv'):\n","\n","    def stratified_group_k_fold(X, y, groups, k, seed=42):\n","\n","        \"\"\"\n","        original author : jakubwasikowski\n","        reference : https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n","        \"\"\"\n","\n","        labels_num = np.max(y) + 1\n","        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n","        y_distr = Counter()\n","        for label, g in zip(y, groups):\n","            y_counts_per_group[g][label] += 1\n","            y_distr[label] += 1\n","\n","        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n","        groups_per_fold = defaultdict(set)\n","\n","        def eval_y_counts_per_fold(y_counts, fold):\n","            y_counts_per_fold[fold] += y_counts\n","            std_per_label = []\n","            for label in range(labels_num):\n","                label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n","                std_per_label.append(label_std)\n","            y_counts_per_fold[fold] -= y_counts\n","            return np.mean(std_per_label)\n","\n","        groups_and_y_counts = list(y_counts_per_group.items())\n","        random.Random(seed).shuffle(groups_and_y_counts)\n","\n","        for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n","            best_fold = None\n","            min_eval = None\n","            for i in range(k):\n","                fold_eval = eval_y_counts_per_fold(y_counts, i)\n","                if min_eval is None or fold_eval < min_eval:\n","                    min_eval = fold_eval\n","                    best_fold = i\n","            y_counts_per_fold[best_fold] += y_counts\n","            groups_per_fold[best_fold].add(g)\n","\n","        all_groups = set(groups)\n","        for i in range(k):\n","            train_groups = all_groups - groups_per_fold[i]\n","            test_groups = groups_per_fold[i]\n","\n","            train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n","            test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n","\n","            yield train_indices, test_indices\n","\n","    df = _df.copy()\n","    le = preprocessing.LabelEncoder()\n","    groups = le.fit_transform(df[group].values)\n","    for n, (train_index, val_index) in enumerate(stratified_group_k_fold(df, df[target], groups, k=k, seed=seed)):\n","        df.loc[val_index, 'fold'] = int(n)\n","    df['fold'] = df['fold'].astype(int)\n","    df[[_id, target, group, 'fold']].to_csv(save_path, index=None)\n","\n","    return df[[_id, target, group, 'fold']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdyJsDCawC-i","colab_type":"code","outputId":"ed3b1d4c-3670-401b-a3e9-6e758c9377fa","executionInfo":{"status":"ok","timestamp":1589734418446,"user_tz":-540,"elapsed":6449,"user":{"displayName":"Yasufumi Nakama","photoUrl":"","userId":"17486303986134302670"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# =====================================================================================\n","# General Settings\n","# =====================================================================================\n","df_path_dict = {'train': CLEAN_ROOT+'train_clean.csv',\n","                'test': CLEAN_ROOT+'test_clean.csv',\n","                'sample_submission': ROOT+'sample_submission.csv'}\n","ID = 'time'\n","TARGET = 'open_channels'\n","seed_everything(seed=CFG.seed)\n","\n","\n","# =====================================================================================\n","# Data Loading\n","# =====================================================================================\n","with timer('Data Loading'):\n","    X_train = pd.read_csv(DRIVE_PATH+'input/data-without-drift/train_clean.csv')\n","    oof_lgb = pd.read_csv(DRIVE_PATH+'input/ion-oof/oof_lightgbm.csv').rename(columns={TARGET:'signal_lgb_oof'})\n","    oof_cat = pd.read_csv(DRIVE_PATH+'input/ion-oof/oof_catboost.csv').rename(columns={TARGET:'signal_cat_oof'})\n","    \n","    X_train = pd.concat([X_train, oof_lgb['signal_lgb_oof']], axis=1)\n","    X_train = pd.concat([X_train, oof_cat['signal_cat_oof']], axis=1)\n","\n","    del oof_lgb, oof_cat; gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Data Loading] start\n","[Data Loading] done in 4 s\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"z_phrJLtwnlL","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Preprocess\n","# =====================================================================================\n","X_train['batch'] = X_train.index // 500000\n","X_train['batch'] = X_train['batch'].astype(int)\n","#X_test['batch'] = X_test.index // 500000\n","#X_test['batch'] = X_test['batch'].astype(int)\n","\n","\n","def signal2cate(X_train, X_test=None, NUM_BINS=1000):\n","    signal_bins = np.linspace(X_train['signal'].min(), X_train['signal'].max(), NUM_BINS + 1)\n","    train_signal_dig = np.digitize(X_train['signal'], bins=signal_bins) - 1\n","    train_signal_dig = np.minimum(train_signal_dig, len(signal_bins) - 2)\n","    X_train['signal_cate'] = train_signal_dig\n","    if X_test is not None:\n","        test_signal_dig = np.digitize(X_test['signal'], bins=signal_bins) - 1\n","        test_signal_dig = np.minimum(test_signal_dig, len(signal_bins) - 2)\n","        X_test['signal_cate'] = test_signal_dig\n","        return  X_train, X_test\n","    return X_train\n","\n","X_train = signal2cate(X_train, X_test=None, NUM_BINS=CFG.total_cate_size)\n","\n","\n","def add_num_features(X_train, X_test=None):\n","    max_signal = X_train['signal'].max()\n","    min_signal = X_train['signal'].min()\n","    X_train['signal_diff_max'] = max_signal - X_train['signal']\n","    X_train['signal_diff_min'] = min_signal - X_train['signal']\n","    if X_test is not None:\n","        X_test['signal_diff_max'] = max_signal - X_test['signal']\n","        X_test['signal_diff_min'] = min_signal - X_test['signal']\n","        return  X_train, X_test\n","    return X_train\n","\n","X_train = add_num_features(X_train, X_test=None)\n","\n","\n","def calc_gradients(df):\n","\n","    df['signal_gradient'] = np.gradient(df['signal'].values)\n","\n","    return df\n","\n","def preprocess_df(df):\n","\n","    output = pd.DataFrame()\n","\n","    for i in range(int(len(df)/500000)):\n","        tmp = df.loc[i * 500000: 500000*(i + 1) - 1].reset_index(drop=True)\n","        tmp = calc_gradients(tmp)\n","        output = pd.concat([output, tmp])\n","\n","    return output.reset_index(drop=True)\n","\n","X_train = preprocess_df(X_train)\n","#X_test = preprocess_df(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-5-3X4kZvZB","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Train functions\n","# =====================================================================================\n","import math\n","from sklearn.metrics import f1_score\n","\n","def lr_schedule(epoch):\n","    if epoch < 30:\n","        lr = CFG.learning_rate\n","    elif epoch < 40:\n","        lr = CFG.learning_rate / 3\n","    elif epoch < 50:\n","        lr = CFG.learning_rate / 5\n","    elif epoch < 60:\n","        lr = CFG.learning_rate / 7\n","    elif epoch < 70:\n","        lr = CFG.learning_rate / 9\n","    elif epoch < 80:\n","        lr = CFG.learning_rate / 11\n","    elif epoch < 90:\n","        lr = CFG.learning_rate / 13\n","    else:\n","        lr = CFG.learning_rate / 100\n","    return lr\n","\n","class MacroF1(Callback):\n","    def __init__(self, model, inputs, targets):\n","        self.model = model\n","        self.inputs = inputs\n","        self.targets = np.argmax(targets, axis=2).reshape(-1)\n","        \n","    def on_epoch_end(self, epoch, logs):\n","        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n","        score = f1_score(self.targets, pred, average='macro')\n","        print(f' - F1Score: {score:.5f}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhuRBMGEwx1N","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Wavenet Model\n","# =====================================================================================\n","def Wavenet_keras(cate_cols, cont_cols):\n","    \n","    def wave_block(x, filters, kernel_size, n):\n","        dilation_rates = [2**i for i in range(n)]\n","        x = Conv1D(filters = filters,\n","                   kernel_size = 1,\n","                   padding = 'same')(x)\n","        res_x = x\n","        for dilation_rate in dilation_rates:\n","            tanh_out = Conv1D(filters = filters,\n","                              kernel_size = kernel_size,\n","                              padding = 'same', \n","                              activation = 'tanh', \n","                              dilation_rate = dilation_rate)(x)\n","            sigm_out = Conv1D(filters = filters,\n","                              kernel_size = kernel_size,\n","                              padding = 'same',\n","                              activation = 'sigmoid', \n","                              dilation_rate = dilation_rate)(x)\n","            x = Multiply()([tanh_out, sigm_out])\n","            x = Conv1D(filters = filters,\n","                       kernel_size = 1,\n","                       padding = 'same')(x)\n","            res_x = Add()([res_x, x])\n","        return res_x\n","    \n","    input1 = Input(shape=(None, len(cont_cols)))\n","    input2 = Input(shape=(None, len(cate_cols)))\n","    # RNN\n","    cate_emb = Embedding(CFG.total_cate_size, CFG.emb_size)(input2)\n","    cate_emb = Reshape((-1, CFG.emb_size*(len(cate_cols))))(cate_emb)\n","    seq_emb = concatenate([cate_emb, input1])\n","    h_gru = Bidirectional(CuDNNGRU(CFG.hidden_size//4, return_sequences=True))(seq_emb) # dropout?\n","    # CNN\n","    cont_x = wave_block(input1, CFG.hidden_size//16, 3, 12)\n","    cont_x = wave_block(cont_x, CFG.hidden_size//8, 3, 8)\n","    cont_x = wave_block(cont_x, CFG.hidden_size//4, 3, 4)\n","    cont_x = wave_block(cont_x, CFG.hidden_size//2, 3, 1)\n","    # CNN & RNN\n","    x = concatenate([cont_x, h_gru])\n","    # fc\n","    x = Dense(11, activation='softmax', name='out')(x)\n","    \n","    model = models.Model(inputs=[input1, input2], outputs=x)\n","    \n","    opt = Adam(lr=CFG.learning_rate)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(loss=losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"owfDXc0kxaAt","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Get Sample function\n","# =====================================================================================\n","def tta_group(X_train):\n","    tmp = X_train[CFG.seq_len//2:len(X_train)-CFG.seq_len//2].reset_index(drop=True)\n","    tmp['tta_group'] = tmp.index // CFG.seq_len\n","    tmp['tta_group'] = tmp['tta_group'] + tmp['group'].nunique()\n","    X_train = pd.concat([X_train[:CFG.seq_len//2], \n","                         tmp, \n","                         X_train[len(X_train)-CFG.seq_len//2:]]).reset_index(drop=True).fillna(-1)\n","    return X_train\n","\n","\"\"\"\n","def tta_group(X_train):\n","    X_train = X_train.reset_index()\n","    tmp = pd.DataFrame()\n","    for i in tqdm(range(int(len(X_train)/500000))):\n","        _tmp = X_train[i*500000+CFG.seq_len//2:(i+1)*500000-CFG.seq_len//2].reset_index(drop=True)\n","        tmp = pd.concat([tmp, _tmp])\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['tta_group'] = tmp.index // CFG.seq_len\n","    tmp['tta_group'] = tmp['tta_group'] + X_train['group'].nunique()\n","    X_train = X_train.merge(tmp[['index', 'tta_group']], on='index', how='left').fillna(-1).drop(columns='index')\n","    return X_train\n","\"\"\"\n","\n","def get_sample_indices(df):\n","    sample_indices = []\n","    group_indices = []\n","    df_groups = df.groupby('group').groups\n","    tta_df_groups = df[df['tta_group']>=0].groupby('tta_group').groups\n","    for group_idx, indices in enumerate(df_groups.values()):\n","        sample_indices.append(indices.values)\n","        group_indices.append(group_idx)\n","    for group_idx, indices in enumerate(tta_df_groups.values()):\n","        sample_indices.append(indices.values)\n","        group_indices.append(group_idx+len(df_groups))\n","    return np.array(sample_indices), group_indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjhF4F66r9Wx","colab_type":"code","colab":{}},"source":["# =====================================================================================\n","# Train loop\n","# =====================================================================================\n","def main(X_train, folds):\n","\n","    seed_everything(CFG.seed)\n","    K.clear_session()\n","    config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","\n","    # =====================================================================================\n","    # Settings\n","    # =====================================================================================\n","    cate_cols = ['signal_cate']\n","    cont_cols = [c for c in X_train.columns if c.find('signal')>=0]\n","    cont_cols = [c for c in cont_cols if c not in cate_cols]\n","    logger.info(f'cont_cols: {cont_cols}')\n","    logger.info(f'cate_cols: {cate_cols}')\n","    target_df = pd.get_dummies(X_train['open_channels'].values)\n","    cont_df = X_train[cont_cols]\n","    cate_df = X_train[cate_cols]\n","\n","    # =====================================================================================\n","    # run function\n","    # =====================================================================================\n","    def run(fold, trn_idx, val_idx):\n","\n","        train_cont_x = np.zeros((len(trn_idx), CFG.seq_len, len(cont_cols)))\n","        train_cate_x = np.zeros((len(trn_idx), CFG.seq_len, len(cate_cols)))\n","        train_y = np.zeros((len(trn_idx), CFG.seq_len, 11))\n","        for i in tqdm_notebook(range(len(trn_idx))):\n","            train_cont_x[i] = cont_df.iloc[sample_indices[trn_idx[i]]].values\n","            train_cate_x[i] = cate_df.iloc[sample_indices[trn_idx[i]]].values     \n","            train_y[i] = target_df.iloc[sample_indices[trn_idx[i]]].values\n","        \n","        val_cont_x = np.zeros((len(val_idx), CFG.seq_len, len(cont_cols)))\n","        val_cate_x = np.zeros((len(val_idx), CFG.seq_len, len(cate_cols)))\n","        val_y = np.zeros((len(val_idx), CFG.seq_len, 11))\n","        for i in tqdm_notebook(range(len(val_idx))):\n","            val_cont_x[i] = cont_df.iloc[sample_indices[val_idx[i]]].values\n","            val_cate_x[i] = cate_df.iloc[sample_indices[val_idx[i]]].values     \n","            val_y[i] = target_df.iloc[sample_indices[val_idx[i]]].values\n","\n","        gc.collect()\n","\n","        # =====================================================================================\n","        # Training loop\n","        # =====================================================================================\n","        model = Wavenet_keras(cate_cols, cont_cols)\n","        cb_lr_schedule = LearningRateScheduler(lr_schedule)\n","        loss_saving_callback = keras.callbacks.ModelCheckpoint(OUTPUT_DIR+f'keras_fold{fold}_best_loss.h5', monitor='val_loss', verbose=1, \n","                                                               save_best_only=True, save_weights_only=True)\n","        score_saving_callback = keras.callbacks.ModelCheckpoint(OUTPUT_DIR+f'keras_fold{fold}_best_score.h5', monitor='val_accuracy', verbose=1, \n","                                                                save_best_only=True, save_weights_only=True)\n","        # ModelCheckpoint追加するとMacroF1Callbackが出力されない...\n","        model.fit([train_cont_x, train_cate_x], train_y, epochs=CFG.num_train_epochs,\n","                  #callbacks=[cb_lr_schedule, loss_saving_callback, score_saving_callback, MacroF1(model, [val_cont_x, val_cate_x], val_y)],\n","                  callbacks=[cb_lr_schedule, loss_saving_callback, score_saving_callback],\n","                  batch_size=CFG.batch_size, verbose=1, validation_data=([val_cont_x, val_cate_x], val_y))\n","        #model.save_weights(OUTPUT_DIR+f'keras_fold{fold}.h5')\n","\n","        # =====================================================================================\n","        # Evaluation\n","        # =====================================================================================\n","        model = Wavenet_keras(cate_cols, cont_cols)\n","        model.load_weights(OUTPUT_DIR+f'keras_fold{fold}_best_score.h5')\n","        preds_f = model.predict([val_cont_x, val_cate_x])\n","        predictions = np.argmax(preds_f, axis=2).reshape(-1)\n","        groundtruth = np.argmax(val_y, axis=2).reshape(-1)\n","        score = f1_score(predictions, groundtruth, labels=list(range(11)), average='macro')\n","        logger.info(f'Training fold {fold} completed. macro f1 score : {score :1.5f}')\n","\n","        return predictions, groundtruth\n","\n","    # =====================================================================================\n","    # k-fold\n","    # =====================================================================================\n","    folds = tta_group(folds)\n","    folds['tta_group'] = folds['tta_group'].astype(int)\n","    sample_indices, group_indices = get_sample_indices(folds)\n","    print(len(group_indices))\n","    print(len(set(group_indices)))\n","    group_map = dict(folds[['group', 'split_group']].values.tolist())\n","    tta_group_map = dict(folds[['tta_group', 'split_group']].values.tolist())\n","    group_map.update(tta_group_map)\n","    group_indices = [group_map[i] for i in group_indices]\n","    print(len(group_indices))\n","    print(len(set(group_indices)))\n","    folds_map = dict(folds[['split_group', 'fold']].values.tolist())\n","    group_indices = [folds_map[i] for i in group_indices]\n","    skf = GroupKFold(n_splits=CFG.n_fold)\n","    splits = [x for x in skf.split(sample_indices, None, group_indices)]\n","    predictions, groundtruth = [], []\n","    for fold, (trn_idx, val_idx) in enumerate(splits):\n","        if fold in CFG.fold:\n","            # with normal val_idx\n","            val_idx = val_idx[val_idx<(5000000//CFG.seq_len)]\n","            with timer(f'##### Running Fold: {fold} #####'):\n","                _predictions, _groundtruth = run(fold, trn_idx, val_idx)\n","                predictions.append(_predictions)\n","                groundtruth.append(_groundtruth)\n","    predictions = np.concatenate(predictions)\n","    groundtruth = np.concatenate(groundtruth)\n","    score = f1_score(predictions, groundtruth, labels=list(range(11)), average='macro')\n","    logger.info(f'##### CV Score: {score} #####')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ID1xqFiseEW","colab_type":"code","outputId":"70b799ed-af37-475b-e091-2652abfe4fd0","executionInfo":{"status":"ok","timestamp":1589757041188,"user_tz":-540,"elapsed":845775,"user":{"displayName":"Yasufumi Nakama","photoUrl":"","userId":"17486303986134302670"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f48239c012fc4ad8a58ca90a5ab3e806","7c441e19a13b4b5d81c0a7d9f64c7af6","55aa5909f2d848268e99e9b821c4e6f3","8b9e0d71bc8042cbb9de6dd2fb90128a","9689886f2d69404385a7c2d876f974a0","34653be3a9e94a5294079fdfcdd690a6","801e38e758d941a4bbde24edab0b4b78","a52f3e84e79945d790f561a068d3acaa","9c77e5325a8640198c001a22289c84be","9afc79aad0ad47e88c2afbece6af7288","61a8f227b0304eda8b10f9244aa9c92c","fce5de95bb6d4e158a91df7a99aec64b","94c41260a0384b108474bc02ff4f768c","f236bfd1d645408492b0186138200c26","49dbb13752d04d35a55131c96dcd28fa","7ba7938cdffd47a0b7ce774f3b7608db","d9fd81998d864a1aab87c47725b73db7","a7669038943841599db83180d03318b9","c9d5cb294feb4dd1b360cb8b7285df18","9712828909e4494b9f50fdd9ad439360","102e5da7bc474e33b07406ab0e8ec122","846d9ab6c2264272aed01665688e47e9","48417965688a45f4864d3b374d41b955","e03a30512ca14c64a275cc0adaf8eda2","45b22000485d41b7b61ae04bf9768c3c","0fc1180bbabb4209899f83758c649a31","b8ed4911dae1484fb0de18efc8ce038e","00cd6c0150e24827884b2e6c53611d3b","a69129e0763b425c93d85ebc230dff28","095055b05707423199863b7438ef2c1d","7fcf641bb134438bb815f84100873cc4","f8e4a2dbb45649c2a949bc81cd701adb","7e75b02dbafe48ef94ee4653d091985a","fc7ffe2db3b74905a17a3228f35733f4","11451f38fc864a1fb943eca5e1cdfd09","6232dab286874ef5a95753e6ea4ac985","8750facf1df84c2d9ccc5e5b0d81f8e0","ae14c777f4474d05af1c40179dbac0ad","ea5306b25c3747c8859ebe26c2664a32","2bf1c47e8e0b49c18529a5d6eedb6c8f","1ad89a4b509f488ea375937d2ae87848","44577303accd48b79af39be799e258d3","b54fce038ef7411fb6ca4905af5d1eaa","00ee61ad46d346ce88f3ca2764c21ce0","44190e8a78664219b8a0e36671344420","3ad16099ff424b2aba63bcab07bad322","05499b8d78f248a1a76ac16d0d0566ae","1613c73333e545e2a4bd23fd4ad59a1a","23a7fe9275394ba1953c8785a735310a","e08634baf311468bb497dc2ab0f661e3","47d6c9dcdfab42b1ae6bdecbd322e5a2","40a5486a2c8d47b5b01a9a7f76e80825","65efb968e29e4cb18c789098000676e1","b982aea6961745be8c6362b868231c74","b05ef2f3caf0498aa0f5b86b785b5d8d","5e293f87493f41e68071f6180a5ea4ca","d3721f923128498fae619fa1930c099d","ba052e17744346bbb74316d28ca6f793","9596c5aa692f466aa1eaac5b9f416869","5b7d20d7e512437398ef40d79aa12019","da9b26660d594009ba9c7eb601a3f768","83e8846d634541b89ac4bf996ab393b5","636d6b422b2b4d0ebab1794cb17e8efe","ac716f26ca404ff0b9a02d9dcb9adfbd"]}},"source":["if __name__ == '__main__':\n","    folds = pd.read_csv(DRIVE_PATH+'input/ion-folds/folds.csv')\n","    folds['group'] = folds.index // CFG.seq_len\n","    main(X_train, folds)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["cont_cols: ['signal', 'signal_lgb_oof', 'signal_cat_oof', 'signal_diff_max', 'signal_diff_min', 'signal_gradient']\n","cate_cols: ['signal_cate']\n"],"name":"stderr"},{"output_type":"stream","text":["1999\n","1999\n","1999\n","500\n"],"name":"stdout"},{"output_type":"stream","text":["[##### Running Fold: 0 #####] start\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f48239c012fc4ad8a58ca90a5ab3e806","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c77e5325a8640198c001a22289c84be","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch 1/110\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","94/94 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.7811\n","Epoch 00001: val_loss improved from inf to 0.16461, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.95279, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 61s 645ms/step - loss: 0.7072 - accuracy: 0.7811 - val_loss: 0.1646 - val_accuracy: 0.9528 - lr: 0.0010\n","Epoch 2/110\n","94/94 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9636\n","Epoch 00002: val_loss improved from 0.16461 to 0.10699, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00002: val_accuracy improved from 0.95279 to 0.96339, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.1150 - accuracy: 0.9636 - val_loss: 0.1070 - val_accuracy: 0.9634 - lr: 0.0010\n","Epoch 3/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9665\n","Epoch 00003: val_loss improved from 0.10699 to 0.10070, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00003: val_accuracy improved from 0.96339 to 0.96446, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0949 - accuracy: 0.9665 - val_loss: 0.1007 - val_accuracy: 0.9645 - lr: 0.0010\n","Epoch 4/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9673\n","Epoch 00004: val_loss improved from 0.10070 to 0.09651, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00004: val_accuracy improved from 0.96446 to 0.96539, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0905 - accuracy: 0.9673 - val_loss: 0.0965 - val_accuracy: 0.9654 - lr: 0.0010\n","Epoch 5/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9677\n","Epoch 00005: val_loss improved from 0.09651 to 0.09512, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00005: val_accuracy improved from 0.96539 to 0.96559, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0883 - accuracy: 0.9677 - val_loss: 0.0951 - val_accuracy: 0.9656 - lr: 0.0010\n","Epoch 6/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9679\n","Epoch 00006: val_loss improved from 0.09512 to 0.09383, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00006: val_accuracy improved from 0.96559 to 0.96584, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0870 - accuracy: 0.9679 - val_loss: 0.0938 - val_accuracy: 0.9658 - lr: 0.0010\n","Epoch 7/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9681\n","Epoch 00007: val_loss improved from 0.09383 to 0.09310, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00007: val_accuracy improved from 0.96584 to 0.96608, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0861 - accuracy: 0.9681 - val_loss: 0.0931 - val_accuracy: 0.9661 - lr: 0.0010\n","Epoch 8/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9677\n","Epoch 00008: val_loss did not improve from 0.09310\n","\n","Epoch 00008: val_accuracy did not improve from 0.96608\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0871 - accuracy: 0.9677 - val_loss: 0.0933 - val_accuracy: 0.9659 - lr: 0.0010\n","Epoch 9/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9682\n","Epoch 00009: val_loss improved from 0.09310 to 0.09214, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00009: val_accuracy improved from 0.96608 to 0.96621, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0855 - accuracy: 0.9682 - val_loss: 0.0921 - val_accuracy: 0.9662 - lr: 0.0010\n","Epoch 10/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9682\n","Epoch 00010: val_loss did not improve from 0.09214\n","\n","Epoch 00010: val_accuracy did not improve from 0.96621\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0851 - accuracy: 0.9682 - val_loss: 0.0932 - val_accuracy: 0.9658 - lr: 0.0010\n","Epoch 11/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9678\n","Epoch 00011: val_loss did not improve from 0.09214\n","\n","Epoch 00011: val_accuracy did not improve from 0.96621\n","94/94 [==============================] - 49s 523ms/step - loss: 0.0865 - accuracy: 0.9678 - val_loss: 0.0950 - val_accuracy: 0.9650 - lr: 0.0010\n","Epoch 12/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9683\n","Epoch 00012: val_loss improved from 0.09214 to 0.09155, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00012: val_accuracy did not improve from 0.96621\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0847 - accuracy: 0.9683 - val_loss: 0.0916 - val_accuracy: 0.9661 - lr: 0.0010\n","Epoch 13/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9684\n","Epoch 00013: val_loss did not improve from 0.09155\n","\n","Epoch 00013: val_accuracy did not improve from 0.96621\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0840 - accuracy: 0.9684 - val_loss: 0.0916 - val_accuracy: 0.9661 - lr: 0.0010\n","Epoch 14/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9677\n","Epoch 00014: val_loss did not improve from 0.09155\n","\n","Epoch 00014: val_accuracy did not improve from 0.96621\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0868 - accuracy: 0.9677 - val_loss: 0.0916 - val_accuracy: 0.9662 - lr: 0.0010\n","Epoch 15/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9685\n","Epoch 00015: val_loss improved from 0.09155 to 0.09013, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00015: val_accuracy improved from 0.96621 to 0.96646, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0836 - accuracy: 0.9685 - val_loss: 0.0901 - val_accuracy: 0.9665 - lr: 0.0010\n","Epoch 16/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9685\n","Epoch 00016: val_loss did not improve from 0.09013\n","\n","Epoch 00016: val_accuracy improved from 0.96646 to 0.96646, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0834 - accuracy: 0.9685 - val_loss: 0.0902 - val_accuracy: 0.9665 - lr: 0.0010\n","Epoch 17/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9686\n","Epoch 00017: val_loss did not improve from 0.09013\n","\n","Epoch 00017: val_accuracy did not improve from 0.96646\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0830 - accuracy: 0.9686 - val_loss: 0.0907 - val_accuracy: 0.9663 - lr: 0.0010\n","Epoch 18/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9685\n","Epoch 00018: val_loss improved from 0.09013 to 0.08957, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00018: val_accuracy improved from 0.96646 to 0.96663, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0832 - accuracy: 0.9685 - val_loss: 0.0896 - val_accuracy: 0.9666 - lr: 0.0010\n","Epoch 19/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9685\n","Epoch 00019: val_loss did not improve from 0.08957\n","\n","Epoch 00019: val_accuracy did not improve from 0.96663\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0833 - accuracy: 0.9685 - val_loss: 0.0896 - val_accuracy: 0.9666 - lr: 0.0010\n","Epoch 20/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9688\n","Epoch 00020: val_loss did not improve from 0.08957\n","\n","Epoch 00020: val_accuracy did not improve from 0.96663\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0823 - accuracy: 0.9688 - val_loss: 0.0903 - val_accuracy: 0.9663 - lr: 0.0010\n","Epoch 21/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9686\n","Epoch 00021: val_loss did not improve from 0.08957\n","\n","Epoch 00021: val_accuracy did not improve from 0.96663\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0830 - accuracy: 0.9686 - val_loss: 0.0939 - val_accuracy: 0.9658 - lr: 0.0010\n","Epoch 22/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9674\n","Epoch 00022: val_loss did not improve from 0.08957\n","\n","Epoch 00022: val_accuracy did not improve from 0.96663\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0879 - accuracy: 0.9674 - val_loss: 0.0914 - val_accuracy: 0.9661 - lr: 0.0010\n","Epoch 23/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9689\n","Epoch 00023: val_loss improved from 0.08957 to 0.08886, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00023: val_accuracy improved from 0.96663 to 0.96676, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0823 - accuracy: 0.9689 - val_loss: 0.0889 - val_accuracy: 0.9668 - lr: 0.0010\n","Epoch 24/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9690\n","Epoch 00024: val_loss did not improve from 0.08886\n","\n","Epoch 00024: val_accuracy improved from 0.96676 to 0.96683, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0815 - accuracy: 0.9690 - val_loss: 0.0892 - val_accuracy: 0.9668 - lr: 0.0010\n","Epoch 25/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9691\n","Epoch 00025: val_loss improved from 0.08886 to 0.08840, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00025: val_accuracy improved from 0.96683 to 0.96695, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0814 - accuracy: 0.9691 - val_loss: 0.0884 - val_accuracy: 0.9670 - lr: 0.0010\n","Epoch 26/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9686\n","Epoch 00026: val_loss did not improve from 0.08840\n","\n","Epoch 00026: val_accuracy did not improve from 0.96695\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0828 - accuracy: 0.9686 - val_loss: 0.0888 - val_accuracy: 0.9668 - lr: 0.0010\n","Epoch 27/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9691\n","Epoch 00027: val_loss did not improve from 0.08840\n","\n","Epoch 00027: val_accuracy improved from 0.96695 to 0.96698, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0810 - accuracy: 0.9691 - val_loss: 0.0889 - val_accuracy: 0.9670 - lr: 0.0010\n","Epoch 28/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9692\n","Epoch 00028: val_loss improved from 0.08840 to 0.08804, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00028: val_accuracy did not improve from 0.96698\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0807 - accuracy: 0.9692 - val_loss: 0.0880 - val_accuracy: 0.9670 - lr: 0.0010\n","Epoch 29/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9685\n","Epoch 00029: val_loss did not improve from 0.08804\n","\n","Epoch 00029: val_accuracy did not improve from 0.96698\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0831 - accuracy: 0.9685 - val_loss: 0.0896 - val_accuracy: 0.9668 - lr: 0.0010\n","Epoch 30/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9691\n","Epoch 00030: val_loss improved from 0.08804 to 0.08733, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00030: val_accuracy improved from 0.96698 to 0.96728, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0811 - accuracy: 0.9691 - val_loss: 0.0873 - val_accuracy: 0.9673 - lr: 0.0010\n","Epoch 31/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9695\n","Epoch 00031: val_loss improved from 0.08733 to 0.08687, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00031: val_accuracy improved from 0.96728 to 0.96737, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0798 - accuracy: 0.9695 - val_loss: 0.0869 - val_accuracy: 0.9674 - lr: 3.3333e-04\n","Epoch 32/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9695\n","Epoch 00032: val_loss improved from 0.08687 to 0.08654, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00032: val_accuracy improved from 0.96737 to 0.96750, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0796 - accuracy: 0.9695 - val_loss: 0.0865 - val_accuracy: 0.9675 - lr: 3.3333e-04\n","Epoch 33/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9695\n","Epoch 00033: val_loss improved from 0.08654 to 0.08642, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00033: val_accuracy improved from 0.96750 to 0.96754, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0797 - accuracy: 0.9695 - val_loss: 0.0864 - val_accuracy: 0.9675 - lr: 3.3333e-04\n","Epoch 34/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9697\n","Epoch 00034: val_loss did not improve from 0.08642\n","\n","Epoch 00034: val_accuracy did not improve from 0.96754\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.0866 - val_accuracy: 0.9674 - lr: 3.3333e-04\n","Epoch 35/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9697\n","Epoch 00035: val_loss did not improve from 0.08642\n","\n","Epoch 00035: val_accuracy did not improve from 0.96754\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.0868 - val_accuracy: 0.9673 - lr: 3.3333e-04\n","Epoch 36/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9697\n","Epoch 00036: val_loss improved from 0.08642 to 0.08635, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00036: val_accuracy did not improve from 0.96754\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.0863 - val_accuracy: 0.9675 - lr: 3.3333e-04\n","Epoch 37/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9697\n","Epoch 00037: val_loss did not improve from 0.08635\n","\n","Epoch 00037: val_accuracy did not improve from 0.96754\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0793 - accuracy: 0.9697 - val_loss: 0.0867 - val_accuracy: 0.9674 - lr: 3.3333e-04\n","Epoch 38/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9697\n","Epoch 00038: val_loss improved from 0.08635 to 0.08605, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00038: val_accuracy did not improve from 0.96754\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.0861 - val_accuracy: 0.9675 - lr: 3.3333e-04\n","Epoch 39/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9697\n","Epoch 00039: val_loss did not improve from 0.08605\n","\n","Epoch 00039: val_accuracy improved from 0.96754 to 0.96756, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0793 - accuracy: 0.9697 - val_loss: 0.0864 - val_accuracy: 0.9676 - lr: 3.3333e-04\n","Epoch 40/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9698\n","Epoch 00040: val_loss improved from 0.08605 to 0.08591, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00040: val_accuracy improved from 0.96756 to 0.96767, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0789 - accuracy: 0.9698 - val_loss: 0.0859 - val_accuracy: 0.9677 - lr: 3.3333e-04\n","Epoch 41/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9699\n","Epoch 00041: val_loss improved from 0.08591 to 0.08573, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00041: val_accuracy improved from 0.96767 to 0.96769, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.0857 - val_accuracy: 0.9677 - lr: 2.0000e-04\n","Epoch 42/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9699\n","Epoch 00042: val_loss improved from 0.08573 to 0.08561, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00042: val_accuracy improved from 0.96769 to 0.96774, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0785 - accuracy: 0.9699 - val_loss: 0.0856 - val_accuracy: 0.9677 - lr: 2.0000e-04\n","Epoch 43/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9699\n","Epoch 00043: val_loss did not improve from 0.08561\n","\n","Epoch 00043: val_accuracy did not improve from 0.96774\n","94/94 [==============================] - 49s 523ms/step - loss: 0.0785 - accuracy: 0.9699 - val_loss: 0.0859 - val_accuracy: 0.9677 - lr: 2.0000e-04\n","Epoch 44/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9699\n","Epoch 00044: val_loss improved from 0.08561 to 0.08547, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00044: val_accuracy improved from 0.96774 to 0.96780, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.0855 - val_accuracy: 0.9678 - lr: 2.0000e-04\n","Epoch 45/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9700\n","Epoch 00045: val_loss improved from 0.08547 to 0.08515, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00045: val_accuracy did not improve from 0.96780\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0784 - accuracy: 0.9700 - val_loss: 0.0851 - val_accuracy: 0.9678 - lr: 2.0000e-04\n","Epoch 46/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9700\n","Epoch 00046: val_loss did not improve from 0.08515\n","\n","Epoch 00046: val_accuracy did not improve from 0.96780\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0783 - accuracy: 0.9700 - val_loss: 0.0854 - val_accuracy: 0.9678 - lr: 2.0000e-04\n","Epoch 47/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9700\n","Epoch 00047: val_loss did not improve from 0.08515\n","\n","Epoch 00047: val_accuracy did not improve from 0.96780\n","94/94 [==============================] - 49s 523ms/step - loss: 0.0783 - accuracy: 0.9700 - val_loss: 0.0854 - val_accuracy: 0.9677 - lr: 2.0000e-04\n","Epoch 48/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9700\n","Epoch 00048: val_loss did not improve from 0.08515\n","\n","Epoch 00048: val_accuracy did not improve from 0.96780\n","94/94 [==============================] - 49s 523ms/step - loss: 0.0782 - accuracy: 0.9700 - val_loss: 0.0853 - val_accuracy: 0.9677 - lr: 2.0000e-04\n","Epoch 49/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9701\n","Epoch 00049: val_loss did not improve from 0.08515\n","\n","Epoch 00049: val_accuracy improved from 0.96780 to 0.96784, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0782 - accuracy: 0.9701 - val_loss: 0.0853 - val_accuracy: 0.9678 - lr: 2.0000e-04\n","Epoch 50/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9700\n","Epoch 00050: val_loss did not improve from 0.08515\n","\n","Epoch 00050: val_accuracy did not improve from 0.96784\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0782 - accuracy: 0.9700 - val_loss: 0.0852 - val_accuracy: 0.9678 - lr: 2.0000e-04\n","Epoch 51/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9701\n","Epoch 00051: val_loss improved from 0.08515 to 0.08490, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00051: val_accuracy improved from 0.96784 to 0.96788, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0781 - accuracy: 0.9701 - val_loss: 0.0849 - val_accuracy: 0.9679 - lr: 1.4286e-04\n","Epoch 52/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9701\n","Epoch 00052: val_loss did not improve from 0.08490\n","\n","Epoch 00052: val_accuracy improved from 0.96788 to 0.96788, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0780 - accuracy: 0.9701 - val_loss: 0.0851 - val_accuracy: 0.9679 - lr: 1.4286e-04\n","Epoch 53/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9701\n","Epoch 00053: val_loss did not improve from 0.08490\n","\n","Epoch 00053: val_accuracy did not improve from 0.96788\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0780 - accuracy: 0.9701 - val_loss: 0.0851 - val_accuracy: 0.9678 - lr: 1.4286e-04\n","Epoch 54/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9701\n","Epoch 00054: val_loss improved from 0.08490 to 0.08485, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00054: val_accuracy improved from 0.96788 to 0.96793, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.0848 - val_accuracy: 0.9679 - lr: 1.4286e-04\n","Epoch 55/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9702\n","Epoch 00055: val_loss did not improve from 0.08485\n","\n","Epoch 00055: val_accuracy did not improve from 0.96793\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0778 - accuracy: 0.9702 - val_loss: 0.0851 - val_accuracy: 0.9679 - lr: 1.4286e-04\n","Epoch 56/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9701\n","Epoch 00056: val_loss did not improve from 0.08485\n","\n","Epoch 00056: val_accuracy did not improve from 0.96793\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.0851 - val_accuracy: 0.9678 - lr: 1.4286e-04\n","Epoch 57/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9701\n","Epoch 00057: val_loss improved from 0.08485 to 0.08469, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00057: val_accuracy did not improve from 0.96793\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.0847 - val_accuracy: 0.9679 - lr: 1.4286e-04\n","Epoch 58/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9701\n","Epoch 00058: val_loss did not improve from 0.08469\n","\n","Epoch 00058: val_accuracy improved from 0.96793 to 0.96794, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0778 - accuracy: 0.9701 - val_loss: 0.0849 - val_accuracy: 0.9679 - lr: 1.4286e-04\n","Epoch 59/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9702\n","Epoch 00059: val_loss did not improve from 0.08469\n","\n","Epoch 00059: val_accuracy improved from 0.96794 to 0.96800, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0777 - accuracy: 0.9702 - val_loss: 0.0848 - val_accuracy: 0.9680 - lr: 1.4286e-04\n","Epoch 60/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9702\n","Epoch 00060: val_loss did not improve from 0.08469\n","\n","Epoch 00060: val_accuracy did not improve from 0.96800\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0777 - accuracy: 0.9702 - val_loss: 0.0850 - val_accuracy: 0.9678 - lr: 1.4286e-04\n","Epoch 61/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9702\n","Epoch 00061: val_loss improved from 0.08469 to 0.08448, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00061: val_accuracy did not improve from 0.96800\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0776 - accuracy: 0.9702 - val_loss: 0.0845 - val_accuracy: 0.9679 - lr: 1.1111e-04\n","Epoch 62/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9702\n","Epoch 00062: val_loss did not improve from 0.08448\n","\n","Epoch 00062: val_accuracy did not improve from 0.96800\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.0845 - val_accuracy: 0.9679 - lr: 1.1111e-04\n","Epoch 63/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9702\n","Epoch 00063: val_loss did not improve from 0.08448\n","\n","Epoch 00063: val_accuracy did not improve from 0.96800\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.0848 - val_accuracy: 0.9679 - lr: 1.1111e-04\n","Epoch 64/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9702\n","Epoch 00064: val_loss improved from 0.08448 to 0.08447, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00064: val_accuracy did not improve from 0.96800\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.0845 - val_accuracy: 0.9679 - lr: 1.1111e-04\n","Epoch 65/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9702\n","Epoch 00065: val_loss improved from 0.08447 to 0.08441, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00065: val_accuracy improved from 0.96800 to 0.96800, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.0844 - val_accuracy: 0.9680 - lr: 1.1111e-04\n","Epoch 66/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9703\n","Epoch 00066: val_loss did not improve from 0.08441\n","\n","Epoch 00066: val_accuracy did not improve from 0.96800\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0775 - accuracy: 0.9703 - val_loss: 0.0846 - val_accuracy: 0.9679 - lr: 1.1111e-04\n","Epoch 67/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9702\n","Epoch 00067: val_loss improved from 0.08441 to 0.08431, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00067: val_accuracy improved from 0.96800 to 0.96802, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 537ms/step - loss: 0.0774 - accuracy: 0.9702 - val_loss: 0.0843 - val_accuracy: 0.9680 - lr: 1.1111e-04\n","Epoch 68/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9703\n","Epoch 00068: val_loss did not improve from 0.08431\n","\n","Epoch 00068: val_accuracy did not improve from 0.96802\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0774 - accuracy: 0.9703 - val_loss: 0.0845 - val_accuracy: 0.9680 - lr: 1.1111e-04\n","Epoch 69/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9703\n","Epoch 00069: val_loss improved from 0.08431 to 0.08423, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00069: val_accuracy did not improve from 0.96802\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0774 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9680 - lr: 1.1111e-04\n","Epoch 70/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9703\n","Epoch 00070: val_loss improved from 0.08423 to 0.08420, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00070: val_accuracy did not improve from 0.96802\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0773 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9680 - lr: 1.1111e-04\n","Epoch 71/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9703\n","Epoch 00071: val_loss improved from 0.08420 to 0.08413, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00071: val_accuracy did not improve from 0.96802\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9680 - lr: 9.0909e-05\n","Epoch 72/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9703\n","Epoch 00072: val_loss did not improve from 0.08413\n","\n","Epoch 00072: val_accuracy did not improve from 0.96802\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0773 - accuracy: 0.9703 - val_loss: 0.0844 - val_accuracy: 0.9679 - lr: 9.0909e-05\n","Epoch 73/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9703\n","Epoch 00073: val_loss did not improve from 0.08413\n","\n","Epoch 00073: val_accuracy improved from 0.96802 to 0.96804, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0773 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9680 - lr: 9.0909e-05\n","Epoch 74/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9703\n","Epoch 00074: val_loss improved from 0.08413 to 0.08413, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00074: val_accuracy improved from 0.96804 to 0.96805, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9681 - lr: 9.0909e-05\n","Epoch 75/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9703\n","Epoch 00075: val_loss did not improve from 0.08413\n","\n","Epoch 00075: val_accuracy did not improve from 0.96805\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9680 - lr: 9.0909e-05\n","Epoch 76/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9703\n","Epoch 00076: val_loss did not improve from 0.08413\n","\n","Epoch 00076: val_accuracy did not improve from 0.96805\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9680 - lr: 9.0909e-05\n","Epoch 77/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00077: val_loss improved from 0.08413 to 0.08407, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00077: val_accuracy did not improve from 0.96805\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9680 - lr: 9.0909e-05\n","Epoch 78/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00078: val_loss did not improve from 0.08407\n","\n","Epoch 00078: val_accuracy improved from 0.96805 to 0.96806, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9681 - lr: 9.0909e-05\n","Epoch 79/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9703\n","Epoch 00079: val_loss did not improve from 0.08407\n","\n","Epoch 00079: val_accuracy did not improve from 0.96806\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9680 - lr: 9.0909e-05\n","Epoch 80/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00080: val_loss improved from 0.08407 to 0.08403, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00080: val_accuracy did not improve from 0.96806\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0840 - val_accuracy: 0.9681 - lr: 9.0909e-05\n","Epoch 81/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00081: val_loss did not improve from 0.08403\n","\n","Epoch 00081: val_accuracy did not improve from 0.96806\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0840 - val_accuracy: 0.9680 - lr: 7.6923e-05\n","Epoch 82/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9703\n","Epoch 00082: val_loss improved from 0.08403 to 0.08395, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00082: val_accuracy improved from 0.96806 to 0.96807, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0770 - accuracy: 0.9703 - val_loss: 0.0840 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 83/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9704\n","Epoch 00083: val_loss improved from 0.08395 to 0.08389, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00083: val_accuracy improved from 0.96807 to 0.96809, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0770 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 84/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00084: val_loss did not improve from 0.08389\n","\n","Epoch 00084: val_accuracy improved from 0.96809 to 0.96813, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0839 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 85/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9704\n","Epoch 00085: val_loss did not improve from 0.08389\n","\n","Epoch 00085: val_accuracy did not improve from 0.96813\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0769 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 86/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9704\n","Epoch 00086: val_loss improved from 0.08389 to 0.08379, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00086: val_accuracy did not improve from 0.96813\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0769 - accuracy: 0.9704 - val_loss: 0.0838 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 87/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9704\n","Epoch 00087: val_loss did not improve from 0.08379\n","\n","Epoch 00087: val_accuracy did not improve from 0.96813\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0769 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9680 - lr: 7.6923e-05\n","Epoch 88/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9704\n","Epoch 00088: val_loss improved from 0.08379 to 0.08370, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00088: val_accuracy did not improve from 0.96813\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0769 - accuracy: 0.9704 - val_loss: 0.0837 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 89/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9704\n","Epoch 00089: val_loss did not improve from 0.08370\n","\n","Epoch 00089: val_accuracy did not improve from 0.96813\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0769 - accuracy: 0.9704 - val_loss: 0.0838 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 90/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9704\n","Epoch 00090: val_loss did not improve from 0.08370\n","\n","Epoch 00090: val_accuracy did not improve from 0.96813\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0769 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9681 - lr: 7.6923e-05\n","Epoch 91/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9705\n","Epoch 00091: val_loss improved from 0.08370 to 0.08367, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00091: val_accuracy improved from 0.96813 to 0.96813, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0767 - accuracy: 0.9705 - val_loss: 0.0837 - val_accuracy: 0.9681 - lr: 1.0000e-05\n","Epoch 92/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9705\n","Epoch 00092: val_loss improved from 0.08367 to 0.08364, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00092: val_accuracy improved from 0.96813 to 0.96814, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0767 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9681 - lr: 1.0000e-05\n","Epoch 93/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00093: val_loss did not improve from 0.08364\n","\n","Epoch 00093: val_accuracy improved from 0.96814 to 0.96817, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 94/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00094: val_loss improved from 0.08364 to 0.08364, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00094: val_accuracy did not improve from 0.96817\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 95/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00095: val_loss improved from 0.08364 to 0.08363, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00095: val_accuracy did not improve from 0.96817\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 96/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00096: val_loss improved from 0.08363 to 0.08362, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00096: val_accuracy did not improve from 0.96817\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 97/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00097: val_loss improved from 0.08362 to 0.08359, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00097: val_accuracy improved from 0.96817 to 0.96818, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 52s 551ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 98/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00098: val_loss did not improve from 0.08359\n","\n","Epoch 00098: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 99/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00099: val_loss did not improve from 0.08359\n","\n","Epoch 00099: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9681 - lr: 1.0000e-05\n","Epoch 100/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00100: val_loss improved from 0.08359 to 0.08359, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00100: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 101/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00101: val_loss did not improve from 0.08359\n","\n","Epoch 00101: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 102/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00102: val_loss did not improve from 0.08359\n","\n","Epoch 00102: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 103/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00103: val_loss did not improve from 0.08359\n","\n","Epoch 00103: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9681 - lr: 1.0000e-05\n","Epoch 104/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00104: val_loss did not improve from 0.08359\n","\n","Epoch 00104: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 105/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00105: val_loss improved from 0.08359 to 0.08358, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_loss.h5\n","\n","Epoch 00105: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 106/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00106: val_loss did not improve from 0.08358\n","\n","Epoch 00106: val_accuracy improved from 0.96818 to 0.96818, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 107/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00107: val_loss did not improve from 0.08358\n","\n","Epoch 00107: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 108/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00108: val_loss did not improve from 0.08358\n","\n","Epoch 00108: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 109/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00109: val_loss did not improve from 0.08358\n","\n","Epoch 00109: val_accuracy did not improve from 0.96818\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n","Epoch 110/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9705\n","Epoch 00110: val_loss did not improve from 0.08358\n","\n","Epoch 00110: val_accuracy improved from 0.96818 to 0.96818, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold0_best_score.h5\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.0836 - val_accuracy: 0.9682 - lr: 1.0000e-05\n"],"name":"stdout"},{"output_type":"stream","text":["Training fold 0 completed. macro f1 score : 0.93960\n","[##### Running Fold: 0 #####] done in 5624 s\n","[##### Running Fold: 1 #####] start\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9fd81998d864a1aab87c47725b73db7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45b22000485d41b7b61ae04bf9768c3c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch 1/110\n","94/94 [==============================] - ETA: 0s - loss: 0.5401 - accuracy: 0.8289\n","Epoch 00001: val_loss improved from inf to 0.13004, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.96250, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 53s 565ms/step - loss: 0.5401 - accuracy: 0.8289 - val_loss: 0.1300 - val_accuracy: 0.9625 - lr: 0.0010\n","Epoch 2/110\n","94/94 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9649\n","Epoch 00002: val_loss improved from 0.13004 to 0.09410, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00002: val_accuracy improved from 0.96250 to 0.96735, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 537ms/step - loss: 0.1080 - accuracy: 0.9649 - val_loss: 0.0941 - val_accuracy: 0.9674 - lr: 0.0010\n","Epoch 3/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9666\n","Epoch 00003: val_loss improved from 0.09410 to 0.08967, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00003: val_accuracy improved from 0.96735 to 0.96796, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0945 - accuracy: 0.9666 - val_loss: 0.0897 - val_accuracy: 0.9680 - lr: 0.0010\n","Epoch 4/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9670\n","Epoch 00004: val_loss improved from 0.08967 to 0.08801, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00004: val_accuracy improved from 0.96796 to 0.96796, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0911 - accuracy: 0.9670 - val_loss: 0.0880 - val_accuracy: 0.9680 - lr: 0.0010\n","Epoch 5/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9671\n","Epoch 00005: val_loss improved from 0.08801 to 0.08673, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00005: val_accuracy improved from 0.96796 to 0.96847, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0898 - accuracy: 0.9671 - val_loss: 0.0867 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 6/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9673\n","Epoch 00006: val_loss improved from 0.08673 to 0.08608, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00006: val_accuracy did not improve from 0.96847\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0886 - accuracy: 0.9673 - val_loss: 0.0861 - val_accuracy: 0.9683 - lr: 0.0010\n","Epoch 7/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9674\n","Epoch 00007: val_loss improved from 0.08608 to 0.08525, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00007: val_accuracy improved from 0.96847 to 0.96847, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0879 - accuracy: 0.9674 - val_loss: 0.0852 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 8/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9663\n","Epoch 00008: val_loss did not improve from 0.08525\n","\n","Epoch 00008: val_accuracy did not improve from 0.96847\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0907 - accuracy: 0.9663 - val_loss: 0.0868 - val_accuracy: 0.9676 - lr: 0.0010\n","Epoch 9/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9673\n","Epoch 00009: val_loss improved from 0.08525 to 0.08487, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00009: val_accuracy did not improve from 0.96847\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0876 - accuracy: 0.9673 - val_loss: 0.0849 - val_accuracy: 0.9684 - lr: 0.0010\n","Epoch 10/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9675\n","Epoch 00010: val_loss improved from 0.08487 to 0.08462, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00010: val_accuracy improved from 0.96847 to 0.96851, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 546ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.0846 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 11/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9675\n","Epoch 00011: val_loss did not improve from 0.08462\n","\n","Epoch 00011: val_accuracy did not improve from 0.96851\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.0849 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 12/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9676\n","Epoch 00012: val_loss improved from 0.08462 to 0.08396, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00012: val_accuracy improved from 0.96851 to 0.96859, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0862 - accuracy: 0.9676 - val_loss: 0.0840 - val_accuracy: 0.9686 - lr: 0.0010\n","Epoch 13/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9674\n","Epoch 00013: val_loss did not improve from 0.08396\n","\n","Epoch 00013: val_accuracy did not improve from 0.96859\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0865 - accuracy: 0.9674 - val_loss: 0.0841 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 14/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9675\n","Epoch 00014: val_loss did not improve from 0.08396\n","\n","Epoch 00014: val_accuracy did not improve from 0.96859\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0864 - accuracy: 0.9675 - val_loss: 0.0845 - val_accuracy: 0.9684 - lr: 0.0010\n","Epoch 15/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9666\n","Epoch 00015: val_loss did not improve from 0.08396\n","\n","Epoch 00015: val_accuracy did not improve from 0.96859\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0886 - accuracy: 0.9666 - val_loss: 0.0844 - val_accuracy: 0.9684 - lr: 0.0010\n","Epoch 16/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9678\n","Epoch 00016: val_loss did not improve from 0.08396\n","\n","Epoch 00016: val_accuracy did not improve from 0.96859\n","94/94 [==============================] - 49s 527ms/step - loss: 0.0849 - accuracy: 0.9678 - val_loss: 0.0855 - val_accuracy: 0.9684 - lr: 0.0010\n","Epoch 17/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9672\n","Epoch 00017: val_loss did not improve from 0.08396\n","\n","Epoch 00017: val_accuracy did not improve from 0.96859\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0868 - accuracy: 0.9672 - val_loss: 0.0843 - val_accuracy: 0.9682 - lr: 0.0010\n","Epoch 18/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9677\n","Epoch 00018: val_loss improved from 0.08396 to 0.08224, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00018: val_accuracy improved from 0.96859 to 0.96893, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 537ms/step - loss: 0.0850 - accuracy: 0.9677 - val_loss: 0.0822 - val_accuracy: 0.9689 - lr: 0.0010\n","Epoch 19/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9679\n","Epoch 00019: val_loss improved from 0.08224 to 0.08217, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00019: val_accuracy improved from 0.96893 to 0.96907, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0844 - accuracy: 0.9679 - val_loss: 0.0822 - val_accuracy: 0.9691 - lr: 0.0010\n","Epoch 20/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9683\n","Epoch 00020: val_loss did not improve from 0.08217\n","\n","Epoch 00020: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0834 - accuracy: 0.9683 - val_loss: 0.0822 - val_accuracy: 0.9690 - lr: 0.0010\n","Epoch 21/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9682\n","Epoch 00021: val_loss improved from 0.08217 to 0.08161, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00021: val_accuracy improved from 0.96907 to 0.96912, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0835 - accuracy: 0.9682 - val_loss: 0.0816 - val_accuracy: 0.9691 - lr: 0.0010\n","Epoch 22/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9682\n","Epoch 00022: val_loss did not improve from 0.08161\n","\n","Epoch 00022: val_accuracy did not improve from 0.96912\n","94/94 [==============================] - 49s 524ms/step - loss: 0.0835 - accuracy: 0.9682 - val_loss: 0.0849 - val_accuracy: 0.9680 - lr: 0.0010\n","Epoch 23/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9672\n","Epoch 00023: val_loss did not improve from 0.08161\n","\n","Epoch 00023: val_accuracy did not improve from 0.96912\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0865 - accuracy: 0.9672 - val_loss: 0.0819 - val_accuracy: 0.9691 - lr: 0.0010\n","Epoch 24/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9683\n","Epoch 00024: val_loss improved from 0.08161 to 0.08123, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00024: val_accuracy improved from 0.96912 to 0.96929, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0831 - accuracy: 0.9683 - val_loss: 0.0812 - val_accuracy: 0.9693 - lr: 0.0010\n","Epoch 25/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9684\n","Epoch 00025: val_loss did not improve from 0.08123\n","\n","Epoch 00025: val_accuracy did not improve from 0.96929\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0828 - accuracy: 0.9684 - val_loss: 0.0815 - val_accuracy: 0.9691 - lr: 0.0010\n","Epoch 26/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9682\n","Epoch 00026: val_loss did not improve from 0.08123\n","\n","Epoch 00026: val_accuracy did not improve from 0.96929\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0834 - accuracy: 0.9682 - val_loss: 0.0837 - val_accuracy: 0.9684 - lr: 0.0010\n","Epoch 27/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9680\n","Epoch 00027: val_loss did not improve from 0.08123\n","\n","Epoch 00027: val_accuracy did not improve from 0.96929\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0840 - accuracy: 0.9680 - val_loss: 0.0818 - val_accuracy: 0.9692 - lr: 0.0010\n","Epoch 28/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9685\n","Epoch 00028: val_loss did not improve from 0.08123\n","\n","Epoch 00028: val_accuracy did not improve from 0.96929\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0823 - accuracy: 0.9685 - val_loss: 0.0818 - val_accuracy: 0.9688 - lr: 0.0010\n","Epoch 29/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9684\n","Epoch 00029: val_loss improved from 0.08123 to 0.08077, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00029: val_accuracy improved from 0.96929 to 0.96934, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0825 - accuracy: 0.9684 - val_loss: 0.0808 - val_accuracy: 0.9693 - lr: 0.0010\n","Epoch 30/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9684\n","Epoch 00030: val_loss did not improve from 0.08077\n","\n","Epoch 00030: val_accuracy did not improve from 0.96934\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0825 - accuracy: 0.9684 - val_loss: 0.0824 - val_accuracy: 0.9689 - lr: 0.0010\n","Epoch 31/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9687\n","Epoch 00031: val_loss improved from 0.08077 to 0.08005, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00031: val_accuracy improved from 0.96934 to 0.96949, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0812 - accuracy: 0.9687 - val_loss: 0.0801 - val_accuracy: 0.9695 - lr: 3.3333e-04\n","Epoch 32/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9688\n","Epoch 00032: val_loss did not improve from 0.08005\n","\n","Epoch 00032: val_accuracy improved from 0.96949 to 0.96950, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0810 - accuracy: 0.9688 - val_loss: 0.0801 - val_accuracy: 0.9695 - lr: 3.3333e-04\n","Epoch 33/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9688\n","Epoch 00033: val_loss improved from 0.08005 to 0.08001, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00033: val_accuracy did not improve from 0.96950\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.0800 - val_accuracy: 0.9695 - lr: 3.3333e-04\n","Epoch 34/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9688\n","Epoch 00034: val_loss improved from 0.08001 to 0.07990, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00034: val_accuracy improved from 0.96950 to 0.96953, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 52s 548ms/step - loss: 0.0809 - accuracy: 0.9688 - val_loss: 0.0799 - val_accuracy: 0.9695 - lr: 3.3333e-04\n","Epoch 35/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9689\n","Epoch 00035: val_loss did not improve from 0.07990\n","\n","Epoch 00035: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0808 - accuracy: 0.9689 - val_loss: 0.0800 - val_accuracy: 0.9694 - lr: 3.3333e-04\n","Epoch 36/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9689\n","Epoch 00036: val_loss did not improve from 0.07990\n","\n","Epoch 00036: val_accuracy improved from 0.96953 to 0.96953, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0808 - accuracy: 0.9689 - val_loss: 0.0800 - val_accuracy: 0.9695 - lr: 3.3333e-04\n","Epoch 37/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9689\n","Epoch 00037: val_loss did not improve from 0.07990\n","\n","Epoch 00037: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 49s 525ms/step - loss: 0.0807 - accuracy: 0.9689 - val_loss: 0.0800 - val_accuracy: 0.9694 - lr: 3.3333e-04\n","Epoch 38/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9688\n","Epoch 00038: val_loss did not improve from 0.07990\n","\n","Epoch 00038: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0808 - accuracy: 0.9688 - val_loss: 0.0800 - val_accuracy: 0.9694 - lr: 3.3333e-04\n","Epoch 39/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9689\n","Epoch 00039: val_loss did not improve from 0.07990\n","\n","Epoch 00039: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 49s 527ms/step - loss: 0.0807 - accuracy: 0.9689 - val_loss: 0.0802 - val_accuracy: 0.9694 - lr: 3.3333e-04\n","Epoch 40/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9689\n","Epoch 00040: val_loss improved from 0.07990 to 0.07984, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00040: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0805 - accuracy: 0.9689 - val_loss: 0.0798 - val_accuracy: 0.9695 - lr: 3.3333e-04\n","Epoch 41/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9690\n","Epoch 00041: val_loss improved from 0.07984 to 0.07953, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00041: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0804 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9695 - lr: 2.0000e-04\n","Epoch 42/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00042: val_loss improved from 0.07953 to 0.07946, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00042: val_accuracy improved from 0.96953 to 0.96960, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9696 - lr: 2.0000e-04\n","Epoch 43/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00043: val_loss did not improve from 0.07946\n","\n","Epoch 00043: val_accuracy did not improve from 0.96960\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9696 - lr: 2.0000e-04\n","Epoch 44/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9689\n","Epoch 00044: val_loss improved from 0.07946 to 0.07942, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00044: val_accuracy did not improve from 0.96960\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0804 - accuracy: 0.9689 - val_loss: 0.0794 - val_accuracy: 0.9695 - lr: 2.0000e-04\n","Epoch 45/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00045: val_loss did not improve from 0.07942\n","\n","Epoch 00045: val_accuracy did not improve from 0.96960\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0794 - val_accuracy: 0.9696 - lr: 2.0000e-04\n","Epoch 46/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00046: val_loss did not improve from 0.07942\n","\n","Epoch 00046: val_accuracy did not improve from 0.96960\n","94/94 [==============================] - 49s 527ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9695 - lr: 2.0000e-04\n","Epoch 47/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9691\n","Epoch 00047: val_loss improved from 0.07942 to 0.07936, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00047: val_accuracy improved from 0.96960 to 0.96962, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0800 - accuracy: 0.9691 - val_loss: 0.0794 - val_accuracy: 0.9696 - lr: 2.0000e-04\n","Epoch 48/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9690\n","Epoch 00048: val_loss did not improve from 0.07936\n","\n","Epoch 00048: val_accuracy did not improve from 0.96962\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0801 - accuracy: 0.9690 - val_loss: 0.0805 - val_accuracy: 0.9692 - lr: 2.0000e-04\n","Epoch 49/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9690\n","Epoch 00049: val_loss improved from 0.07936 to 0.07925, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00049: val_accuracy improved from 0.96962 to 0.96963, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0801 - accuracy: 0.9690 - val_loss: 0.0793 - val_accuracy: 0.9696 - lr: 2.0000e-04\n","Epoch 50/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9691\n","Epoch 00050: val_loss did not improve from 0.07925\n","\n","Epoch 00050: val_accuracy did not improve from 0.96963\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0799 - accuracy: 0.9691 - val_loss: 0.0794 - val_accuracy: 0.9696 - lr: 2.0000e-04\n","Epoch 51/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9691\n","Epoch 00051: val_loss improved from 0.07925 to 0.07921, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00051: val_accuracy improved from 0.96963 to 0.96966, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.0792 - val_accuracy: 0.9697 - lr: 1.4286e-04\n","Epoch 52/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9691\n","Epoch 00052: val_loss improved from 0.07921 to 0.07914, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00052: val_accuracy improved from 0.96966 to 0.96967, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.0791 - val_accuracy: 0.9697 - lr: 1.4286e-04\n","Epoch 53/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9692\n","Epoch 00053: val_loss improved from 0.07914 to 0.07901, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00053: val_accuracy improved from 0.96967 to 0.96970, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0796 - accuracy: 0.9692 - val_loss: 0.0790 - val_accuracy: 0.9697 - lr: 1.4286e-04\n","Epoch 54/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9692\n","Epoch 00054: val_loss did not improve from 0.07901\n","\n","Epoch 00054: val_accuracy improved from 0.96970 to 0.96971, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0797 - accuracy: 0.9692 - val_loss: 0.0791 - val_accuracy: 0.9697 - lr: 1.4286e-04\n","Epoch 55/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9692\n","Epoch 00055: val_loss did not improve from 0.07901\n","\n","Epoch 00055: val_accuracy improved from 0.96971 to 0.96972, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0796 - accuracy: 0.9692 - val_loss: 0.0790 - val_accuracy: 0.9697 - lr: 1.4286e-04\n","Epoch 56/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9692\n","Epoch 00056: val_loss did not improve from 0.07901\n","\n","Epoch 00056: val_accuracy did not improve from 0.96972\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0796 - accuracy: 0.9692 - val_loss: 0.0796 - val_accuracy: 0.9695 - lr: 1.4286e-04\n","Epoch 57/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9692\n","Epoch 00057: val_loss improved from 0.07901 to 0.07887, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00057: val_accuracy improved from 0.96972 to 0.96983, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 52s 553ms/step - loss: 0.0796 - accuracy: 0.9692 - val_loss: 0.0789 - val_accuracy: 0.9698 - lr: 1.4286e-04\n","Epoch 58/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00058: val_loss did not improve from 0.07887\n","\n","Epoch 00058: val_accuracy did not improve from 0.96983\n","94/94 [==============================] - 49s 526ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0789 - val_accuracy: 0.9698 - lr: 1.4286e-04\n","Epoch 59/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00059: val_loss did not improve from 0.07887\n","\n","Epoch 00059: val_accuracy did not improve from 0.96983\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0791 - val_accuracy: 0.9697 - lr: 1.4286e-04\n","Epoch 60/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9693\n","Epoch 00060: val_loss did not improve from 0.07887\n","\n","Epoch 00060: val_accuracy did not improve from 0.96983\n","94/94 [==============================] - 50s 527ms/step - loss: 0.0793 - accuracy: 0.9693 - val_loss: 0.0790 - val_accuracy: 0.9698 - lr: 1.4286e-04\n","Epoch 61/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9693\n","Epoch 00061: val_loss improved from 0.07887 to 0.07867, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00061: val_accuracy improved from 0.96983 to 0.96987, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0792 - accuracy: 0.9693 - val_loss: 0.0787 - val_accuracy: 0.9699 - lr: 1.1111e-04\n","Epoch 62/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9694\n","Epoch 00062: val_loss improved from 0.07867 to 0.07866, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00062: val_accuracy did not improve from 0.96987\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0791 - accuracy: 0.9694 - val_loss: 0.0787 - val_accuracy: 0.9698 - lr: 1.1111e-04\n","Epoch 63/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9694\n","Epoch 00063: val_loss improved from 0.07866 to 0.07851, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00063: val_accuracy improved from 0.96987 to 0.96993, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0791 - accuracy: 0.9694 - val_loss: 0.0785 - val_accuracy: 0.9699 - lr: 1.1111e-04\n","Epoch 64/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9694\n","Epoch 00064: val_loss did not improve from 0.07851\n","\n","Epoch 00064: val_accuracy improved from 0.96993 to 0.96996, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.0785 - val_accuracy: 0.9700 - lr: 1.1111e-04\n","Epoch 65/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9695\n","Epoch 00065: val_loss improved from 0.07851 to 0.07823, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00065: val_accuracy improved from 0.96996 to 0.97013, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.0782 - val_accuracy: 0.9701 - lr: 1.1111e-04\n","Epoch 66/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9695\n","Epoch 00066: val_loss improved from 0.07823 to 0.07813, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00066: val_accuracy improved from 0.97013 to 0.97017, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0788 - accuracy: 0.9695 - val_loss: 0.0781 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 67/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9696\n","Epoch 00067: val_loss improved from 0.07813 to 0.07761, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00067: val_accuracy improved from 0.97017 to 0.97035, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0786 - accuracy: 0.9696 - val_loss: 0.0776 - val_accuracy: 0.9704 - lr: 1.1111e-04\n","Epoch 68/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9697\n","Epoch 00068: val_loss improved from 0.07761 to 0.07729, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00068: val_accuracy improved from 0.97035 to 0.97056, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0783 - accuracy: 0.9697 - val_loss: 0.0773 - val_accuracy: 0.9706 - lr: 1.1111e-04\n","Epoch 69/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9699\n","Epoch 00069: val_loss improved from 0.07729 to 0.07720, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00069: val_accuracy improved from 0.97056 to 0.97058, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0781 - accuracy: 0.9699 - val_loss: 0.0772 - val_accuracy: 0.9706 - lr: 1.1111e-04\n","Epoch 70/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9700\n","Epoch 00070: val_loss improved from 0.07720 to 0.07655, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00070: val_accuracy improved from 0.97058 to 0.97082, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0778 - accuracy: 0.9700 - val_loss: 0.0765 - val_accuracy: 0.9708 - lr: 1.1111e-04\n","Epoch 71/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9701\n","Epoch 00071: val_loss improved from 0.07655 to 0.07635, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00071: val_accuracy improved from 0.97082 to 0.97093, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0775 - accuracy: 0.9701 - val_loss: 0.0764 - val_accuracy: 0.9709 - lr: 9.0909e-05\n","Epoch 72/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9701\n","Epoch 00072: val_loss did not improve from 0.07635\n","\n","Epoch 00072: val_accuracy did not improve from 0.97093\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0774 - accuracy: 0.9701 - val_loss: 0.0765 - val_accuracy: 0.9709 - lr: 9.0909e-05\n","Epoch 73/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9701\n","Epoch 00073: val_loss did not improve from 0.07635\n","\n","Epoch 00073: val_accuracy did not improve from 0.97093\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0773 - accuracy: 0.9701 - val_loss: 0.0764 - val_accuracy: 0.9708 - lr: 9.0909e-05\n","Epoch 74/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00074: val_loss improved from 0.07635 to 0.07624, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00074: val_accuracy improved from 0.97093 to 0.97096, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0762 - val_accuracy: 0.9710 - lr: 9.0909e-05\n","Epoch 75/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00075: val_loss did not improve from 0.07624\n","\n","Epoch 00075: val_accuracy improved from 0.97096 to 0.97097, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0763 - val_accuracy: 0.9710 - lr: 9.0909e-05\n","Epoch 76/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00076: val_loss improved from 0.07624 to 0.07620, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00076: val_accuracy did not improve from 0.97097\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0762 - val_accuracy: 0.9710 - lr: 9.0909e-05\n","Epoch 77/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9702\n","Epoch 00077: val_loss did not improve from 0.07620\n","\n","Epoch 00077: val_accuracy did not improve from 0.97097\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0771 - accuracy: 0.9702 - val_loss: 0.0763 - val_accuracy: 0.9709 - lr: 9.0909e-05\n","Epoch 78/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9702\n","Epoch 00078: val_loss improved from 0.07620 to 0.07611, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00078: val_accuracy improved from 0.97097 to 0.97104, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0771 - accuracy: 0.9702 - val_loss: 0.0761 - val_accuracy: 0.9710 - lr: 9.0909e-05\n","Epoch 79/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9702\n","Epoch 00079: val_loss did not improve from 0.07611\n","\n","Epoch 00079: val_accuracy did not improve from 0.97104\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0770 - accuracy: 0.9702 - val_loss: 0.0762 - val_accuracy: 0.9710 - lr: 9.0909e-05\n","Epoch 80/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9702\n","Epoch 00080: val_loss improved from 0.07611 to 0.07609, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00080: val_accuracy did not improve from 0.97104\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0770 - accuracy: 0.9702 - val_loss: 0.0761 - val_accuracy: 0.9710 - lr: 9.0909e-05\n","Epoch 81/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9703\n","Epoch 00081: val_loss did not improve from 0.07609\n","\n","Epoch 00081: val_accuracy did not improve from 0.97104\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0769 - accuracy: 0.9703 - val_loss: 0.0761 - val_accuracy: 0.9710 - lr: 7.6923e-05\n","Epoch 82/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9702\n","Epoch 00082: val_loss improved from 0.07609 to 0.07598, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00082: val_accuracy improved from 0.97104 to 0.97105, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0769 - accuracy: 0.9702 - val_loss: 0.0760 - val_accuracy: 0.9710 - lr: 7.6923e-05\n","Epoch 83/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00083: val_loss improved from 0.07598 to 0.07592, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00083: val_accuracy improved from 0.97105 to 0.97108, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0759 - val_accuracy: 0.9711 - lr: 7.6923e-05\n","Epoch 84/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00084: val_loss did not improve from 0.07592\n","\n","Epoch 00084: val_accuracy did not improve from 0.97108\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0761 - val_accuracy: 0.9710 - lr: 7.6923e-05\n","Epoch 85/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00085: val_loss did not improve from 0.07592\n","\n","Epoch 00085: val_accuracy did not improve from 0.97108\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0761 - val_accuracy: 0.9710 - lr: 7.6923e-05\n","Epoch 86/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00086: val_loss did not improve from 0.07592\n","\n","Epoch 00086: val_accuracy did not improve from 0.97108\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0760 - val_accuracy: 0.9711 - lr: 7.6923e-05\n","Epoch 87/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00087: val_loss improved from 0.07592 to 0.07589, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00087: val_accuracy did not improve from 0.97108\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0759 - val_accuracy: 0.9711 - lr: 7.6923e-05\n","Epoch 88/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9703\n","Epoch 00088: val_loss improved from 0.07589 to 0.07583, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00088: val_accuracy improved from 0.97108 to 0.97110, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0767 - accuracy: 0.9703 - val_loss: 0.0758 - val_accuracy: 0.9711 - lr: 7.6923e-05\n","Epoch 89/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9703\n","Epoch 00089: val_loss did not improve from 0.07583\n","\n","Epoch 00089: val_accuracy did not improve from 0.97110\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0767 - accuracy: 0.9703 - val_loss: 0.0759 - val_accuracy: 0.9711 - lr: 7.6923e-05\n","Epoch 90/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9703\n","Epoch 00090: val_loss did not improve from 0.07583\n","\n","Epoch 00090: val_accuracy did not improve from 0.97110\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0767 - accuracy: 0.9703 - val_loss: 0.0758 - val_accuracy: 0.9711 - lr: 7.6923e-05\n","Epoch 91/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9704\n","Epoch 00091: val_loss improved from 0.07583 to 0.07575, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00091: val_accuracy improved from 0.97110 to 0.97112, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.0758 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 92/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9704\n","Epoch 00092: val_loss did not improve from 0.07575\n","\n","Epoch 00092: val_accuracy did not improve from 0.97112\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.0758 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 93/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00093: val_loss improved from 0.07575 to 0.07574, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00093: val_accuracy improved from 0.97112 to 0.97114, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 94/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9704\n","Epoch 00094: val_loss improved from 0.07574 to 0.07574, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00094: val_accuracy did not improve from 0.97114\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 95/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00095: val_loss improved from 0.07574 to 0.07574, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00095: val_accuracy improved from 0.97114 to 0.97116, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 51s 547ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9712 - lr: 1.0000e-05\n","Epoch 96/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00096: val_loss did not improve from 0.07574\n","\n","Epoch 00096: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 97/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00097: val_loss improved from 0.07574 to 0.07573, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00097: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9712 - lr: 1.0000e-05\n","Epoch 98/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00098: val_loss improved from 0.07573 to 0.07572, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00098: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 99/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00099: val_loss improved from 0.07572 to 0.07572, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00099: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 100/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00100: val_loss did not improve from 0.07572\n","\n","Epoch 00100: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 101/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00101: val_loss did not improve from 0.07572\n","\n","Epoch 00101: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 102/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00102: val_loss improved from 0.07572 to 0.07571, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00102: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9712 - lr: 1.0000e-05\n","Epoch 103/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00103: val_loss did not improve from 0.07571\n","\n","Epoch 00103: val_accuracy did not improve from 0.97116\n","94/94 [==============================] - 50s 528ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 104/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00104: val_loss did not improve from 0.07571\n","\n","Epoch 00104: val_accuracy improved from 0.97116 to 0.97118, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9712 - lr: 1.0000e-05\n","Epoch 105/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00105: val_loss improved from 0.07571 to 0.07570, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00105: val_accuracy did not improve from 0.97118\n","94/94 [==============================] - 52s 551ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 106/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00106: val_loss did not improve from 0.07570\n","\n","Epoch 00106: val_accuracy did not improve from 0.97118\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 107/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00107: val_loss did not improve from 0.07570\n","\n","Epoch 00107: val_accuracy did not improve from 0.97118\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 108/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00108: val_loss did not improve from 0.07570\n","\n","Epoch 00108: val_accuracy did not improve from 0.97118\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9711 - lr: 1.0000e-05\n","Epoch 109/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00109: val_loss improved from 0.07570 to 0.07570, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold1_best_loss.h5\n","\n","Epoch 00109: val_accuracy did not improve from 0.97118\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9712 - lr: 1.0000e-05\n","Epoch 110/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9704\n","Epoch 00110: val_loss did not improve from 0.07570\n","\n","Epoch 00110: val_accuracy did not improve from 0.97118\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.0757 - val_accuracy: 0.9712 - lr: 1.0000e-05\n"],"name":"stdout"},{"output_type":"stream","text":["Training fold 1 completed. macro f1 score : 0.94262\n","[##### Running Fold: 1 #####] done in 5623 s\n","[##### Running Fold: 2 #####] start\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e75b02dbafe48ef94ee4653d091985a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1499.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ad89a4b509f488ea375937d2ae87848","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch 1/110\n","94/94 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.7858\n","Epoch 00001: val_loss improved from inf to 0.13766, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.96206, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 53s 566ms/step - loss: 0.6643 - accuracy: 0.7858 - val_loss: 0.1377 - val_accuracy: 0.9621 - lr: 0.0010\n","Epoch 2/110\n","94/94 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9654\n","Epoch 00002: val_loss improved from 0.13766 to 0.09426, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00002: val_accuracy improved from 0.96206 to 0.96676, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.1074 - accuracy: 0.9654 - val_loss: 0.0943 - val_accuracy: 0.9668 - lr: 0.0010\n","Epoch 3/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9665\n","Epoch 00003: val_loss improved from 0.09426 to 0.09241, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00003: val_accuracy did not improve from 0.96676\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0947 - accuracy: 0.9665 - val_loss: 0.0924 - val_accuracy: 0.9663 - lr: 0.0010\n","Epoch 4/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9669\n","Epoch 00004: val_loss improved from 0.09241 to 0.08899, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00004: val_accuracy improved from 0.96676 to 0.96728, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0915 - accuracy: 0.9669 - val_loss: 0.0890 - val_accuracy: 0.9673 - lr: 0.0010\n","Epoch 5/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9671\n","Epoch 00005: val_loss improved from 0.08899 to 0.08838, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00005: val_accuracy improved from 0.96728 to 0.96733, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0903 - accuracy: 0.9671 - val_loss: 0.0884 - val_accuracy: 0.9673 - lr: 0.0010\n","Epoch 6/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9669\n","Epoch 00006: val_loss improved from 0.08838 to 0.08656, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00006: val_accuracy improved from 0.96733 to 0.96776, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0903 - accuracy: 0.9669 - val_loss: 0.0866 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 7/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9673\n","Epoch 00007: val_loss did not improve from 0.08656\n","\n","Epoch 00007: val_accuracy did not improve from 0.96776\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0887 - accuracy: 0.9673 - val_loss: 0.0875 - val_accuracy: 0.9675 - lr: 0.0010\n","Epoch 8/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9674\n","Epoch 00008: val_loss improved from 0.08656 to 0.08578, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00008: val_accuracy improved from 0.96776 to 0.96778, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0882 - accuracy: 0.9674 - val_loss: 0.0858 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 9/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9676\n","Epoch 00009: val_loss did not improve from 0.08578\n","\n","Epoch 00009: val_accuracy improved from 0.96778 to 0.96784, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0872 - accuracy: 0.9676 - val_loss: 0.0869 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 10/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9673\n","Epoch 00010: val_loss improved from 0.08578 to 0.08499, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00010: val_accuracy improved from 0.96784 to 0.96803, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0881 - accuracy: 0.9673 - val_loss: 0.0850 - val_accuracy: 0.9680 - lr: 0.0010\n","Epoch 11/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9677\n","Epoch 00011: val_loss did not improve from 0.08499\n","\n","Epoch 00011: val_accuracy improved from 0.96803 to 0.96812, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0868 - accuracy: 0.9677 - val_loss: 0.0850 - val_accuracy: 0.9681 - lr: 0.0010\n","Epoch 12/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9668\n","Epoch 00012: val_loss did not improve from 0.08499\n","\n","Epoch 00012: val_accuracy did not improve from 0.96812\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0895 - accuracy: 0.9668 - val_loss: 0.0997 - val_accuracy: 0.9631 - lr: 0.0010\n","Epoch 13/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9674\n","Epoch 00013: val_loss improved from 0.08499 to 0.08415, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00013: val_accuracy improved from 0.96812 to 0.96815, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0874 - accuracy: 0.9674 - val_loss: 0.0841 - val_accuracy: 0.9681 - lr: 0.0010\n","Epoch 14/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9678\n","Epoch 00014: val_loss did not improve from 0.08415\n","\n","Epoch 00014: val_accuracy did not improve from 0.96815\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0859 - accuracy: 0.9678 - val_loss: 0.0847 - val_accuracy: 0.9681 - lr: 0.0010\n","Epoch 15/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9675\n","Epoch 00015: val_loss improved from 0.08415 to 0.08335, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00015: val_accuracy improved from 0.96815 to 0.96836, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.0834 - val_accuracy: 0.9684 - lr: 0.0010\n","Epoch 16/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9678\n","Epoch 00016: val_loss did not improve from 0.08335\n","\n","Epoch 00016: val_accuracy did not improve from 0.96836\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0858 - accuracy: 0.9678 - val_loss: 0.0844 - val_accuracy: 0.9682 - lr: 0.0010\n","Epoch 17/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9677\n","Epoch 00017: val_loss did not improve from 0.08335\n","\n","Epoch 00017: val_accuracy did not improve from 0.96836\n","94/94 [==============================] - 52s 549ms/step - loss: 0.0860 - accuracy: 0.9677 - val_loss: 0.0839 - val_accuracy: 0.9681 - lr: 0.0010\n","Epoch 18/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9678\n","Epoch 00018: val_loss did not improve from 0.08335\n","\n","Epoch 00018: val_accuracy did not improve from 0.96836\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0856 - accuracy: 0.9678 - val_loss: 0.0850 - val_accuracy: 0.9681 - lr: 0.0010\n","Epoch 19/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9677\n","Epoch 00019: val_loss improved from 0.08335 to 0.08318, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00019: val_accuracy did not improve from 0.96836\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0859 - accuracy: 0.9677 - val_loss: 0.0832 - val_accuracy: 0.9683 - lr: 0.0010\n","Epoch 20/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9680\n","Epoch 00020: val_loss did not improve from 0.08318\n","\n","Epoch 00020: val_accuracy did not improve from 0.96836\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0846 - accuracy: 0.9680 - val_loss: 0.0833 - val_accuracy: 0.9683 - lr: 0.0010\n","Epoch 21/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9682\n","Epoch 00021: val_loss improved from 0.08318 to 0.08271, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00021: val_accuracy improved from 0.96836 to 0.96849, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 547ms/step - loss: 0.0838 - accuracy: 0.9682 - val_loss: 0.0827 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 22/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9678\n","Epoch 00022: val_loss did not improve from 0.08271\n","\n","Epoch 00022: val_accuracy did not improve from 0.96849\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0854 - accuracy: 0.9678 - val_loss: 0.0860 - val_accuracy: 0.9672 - lr: 0.0010\n","Epoch 23/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9682\n","Epoch 00023: val_loss improved from 0.08271 to 0.08054, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00023: val_accuracy improved from 0.96849 to 0.96915, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 547ms/step - loss: 0.0841 - accuracy: 0.9682 - val_loss: 0.0805 - val_accuracy: 0.9691 - lr: 0.0010\n","Epoch 24/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9690\n","Epoch 00024: val_loss did not improve from 0.08054\n","\n","Epoch 00024: val_accuracy did not improve from 0.96915\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0820 - accuracy: 0.9690 - val_loss: 0.0823 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 25/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9689\n","Epoch 00025: val_loss improved from 0.08054 to 0.08025, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00025: val_accuracy improved from 0.96915 to 0.96941, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 52s 548ms/step - loss: 0.0822 - accuracy: 0.9689 - val_loss: 0.0802 - val_accuracy: 0.9694 - lr: 0.0010\n","Epoch 26/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9682\n","Epoch 00026: val_loss did not improve from 0.08025\n","\n","Epoch 00026: val_accuracy did not improve from 0.96941\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0849 - accuracy: 0.9682 - val_loss: 0.0819 - val_accuracy: 0.9690 - lr: 0.0010\n","Epoch 27/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9692\n","Epoch 00027: val_loss did not improve from 0.08025\n","\n","Epoch 00027: val_accuracy improved from 0.96941 to 0.96946, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0812 - accuracy: 0.9692 - val_loss: 0.0806 - val_accuracy: 0.9695 - lr: 0.0010\n","Epoch 28/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9694\n","Epoch 00028: val_loss improved from 0.08025 to 0.07983, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00028: val_accuracy improved from 0.96946 to 0.96956, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0807 - accuracy: 0.9694 - val_loss: 0.0798 - val_accuracy: 0.9696 - lr: 0.0010\n","Epoch 29/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9694\n","Epoch 00029: val_loss improved from 0.07983 to 0.07982, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00029: val_accuracy improved from 0.96956 to 0.96965, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0808 - accuracy: 0.9694 - val_loss: 0.0798 - val_accuracy: 0.9697 - lr: 0.0010\n","Epoch 30/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9696\n","Epoch 00030: val_loss improved from 0.07982 to 0.07850, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00030: val_accuracy improved from 0.96965 to 0.96994, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0799 - accuracy: 0.9696 - val_loss: 0.0785 - val_accuracy: 0.9699 - lr: 0.0010\n","Epoch 31/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9699\n","Epoch 00031: val_loss improved from 0.07850 to 0.07824, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00031: val_accuracy did not improve from 0.96994\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.0782 - val_accuracy: 0.9699 - lr: 3.3333e-04\n","Epoch 32/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9699\n","Epoch 00032: val_loss improved from 0.07824 to 0.07800, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00032: val_accuracy improved from 0.96994 to 0.97000, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0788 - accuracy: 0.9699 - val_loss: 0.0780 - val_accuracy: 0.9700 - lr: 3.3333e-04\n","Epoch 33/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9699\n","Epoch 00033: val_loss did not improve from 0.07800\n","\n","Epoch 00033: val_accuracy did not improve from 0.97000\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0788 - accuracy: 0.9699 - val_loss: 0.0780 - val_accuracy: 0.9700 - lr: 3.3333e-04\n","Epoch 34/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9699\n","Epoch 00034: val_loss did not improve from 0.07800\n","\n","Epoch 00034: val_accuracy did not improve from 0.97000\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.0781 - val_accuracy: 0.9700 - lr: 3.3333e-04\n","Epoch 35/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9699\n","Epoch 00035: val_loss improved from 0.07800 to 0.07788, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00035: val_accuracy improved from 0.97000 to 0.97003, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.0779 - val_accuracy: 0.9700 - lr: 3.3333e-04\n","Epoch 36/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9700\n","Epoch 00036: val_loss improved from 0.07788 to 0.07783, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00036: val_accuracy improved from 0.97003 to 0.97009, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.0778 - val_accuracy: 0.9701 - lr: 3.3333e-04\n","Epoch 37/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9699\n","Epoch 00037: val_loss improved from 0.07783 to 0.07777, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00037: val_accuracy did not improve from 0.97009\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.0778 - val_accuracy: 0.9700 - lr: 3.3333e-04\n","Epoch 38/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9700\n","Epoch 00038: val_loss did not improve from 0.07777\n","\n","Epoch 00038: val_accuracy did not improve from 0.97009\n","94/94 [==============================] - 50s 529ms/step - loss: 0.0784 - accuracy: 0.9700 - val_loss: 0.0781 - val_accuracy: 0.9700 - lr: 3.3333e-04\n","Epoch 39/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9699\n","Epoch 00039: val_loss did not improve from 0.07777\n","\n","Epoch 00039: val_accuracy did not improve from 0.97009\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0785 - accuracy: 0.9699 - val_loss: 0.0781 - val_accuracy: 0.9699 - lr: 3.3333e-04\n","Epoch 40/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9700\n","Epoch 00040: val_loss did not improve from 0.07777\n","\n","Epoch 00040: val_accuracy improved from 0.97009 to 0.97015, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0783 - accuracy: 0.9700 - val_loss: 0.0778 - val_accuracy: 0.9702 - lr: 3.3333e-04\n","Epoch 41/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9701\n","Epoch 00041: val_loss improved from 0.07777 to 0.07760, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00041: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 52s 558ms/step - loss: 0.0781 - accuracy: 0.9701 - val_loss: 0.0776 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 42/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9701\n","Epoch 00042: val_loss did not improve from 0.07760\n","\n","Epoch 00042: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0780 - accuracy: 0.9701 - val_loss: 0.0777 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 43/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9700\n","Epoch 00043: val_loss improved from 0.07760 to 0.07748, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00043: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0780 - accuracy: 0.9700 - val_loss: 0.0775 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 44/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9701\n","Epoch 00044: val_loss did not improve from 0.07748\n","\n","Epoch 00044: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0781 - accuracy: 0.9701 - val_loss: 0.0776 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 45/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9701\n","Epoch 00045: val_loss did not improve from 0.07748\n","\n","Epoch 00045: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0780 - accuracy: 0.9701 - val_loss: 0.0776 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 46/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9701\n","Epoch 00046: val_loss did not improve from 0.07748\n","\n","Epoch 00046: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0780 - accuracy: 0.9701 - val_loss: 0.0775 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 47/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9701\n","Epoch 00047: val_loss did not improve from 0.07748\n","\n","Epoch 00047: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.0778 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 48/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9701\n","Epoch 00048: val_loss did not improve from 0.07748\n","\n","Epoch 00048: val_accuracy did not improve from 0.97015\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.0775 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 49/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9701\n","Epoch 00049: val_loss improved from 0.07748 to 0.07736, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00049: val_accuracy improved from 0.97015 to 0.97016, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0778 - accuracy: 0.9701 - val_loss: 0.0774 - val_accuracy: 0.9702 - lr: 2.0000e-04\n","Epoch 50/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9701\n","Epoch 00050: val_loss did not improve from 0.07736\n","\n","Epoch 00050: val_accuracy did not improve from 0.97016\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0777 - accuracy: 0.9701 - val_loss: 0.0774 - val_accuracy: 0.9701 - lr: 2.0000e-04\n","Epoch 51/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9702\n","Epoch 00051: val_loss did not improve from 0.07736\n","\n","Epoch 00051: val_accuracy did not improve from 0.97016\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0776 - accuracy: 0.9702 - val_loss: 0.0774 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 52/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9702\n","Epoch 00052: val_loss improved from 0.07736 to 0.07733, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00052: val_accuracy did not improve from 0.97016\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0776 - accuracy: 0.9702 - val_loss: 0.0773 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 53/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9702\n","Epoch 00053: val_loss improved from 0.07733 to 0.07729, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00053: val_accuracy did not improve from 0.97016\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.0773 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 54/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9701\n","Epoch 00054: val_loss did not improve from 0.07729\n","\n","Epoch 00054: val_accuracy did not improve from 0.97016\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0776 - accuracy: 0.9701 - val_loss: 0.0774 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 55/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9702\n","Epoch 00055: val_loss improved from 0.07729 to 0.07727, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00055: val_accuracy improved from 0.97016 to 0.97020, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.0773 - val_accuracy: 0.9702 - lr: 1.4286e-04\n","Epoch 56/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9702\n","Epoch 00056: val_loss improved from 0.07727 to 0.07721, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00056: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0774 - accuracy: 0.9702 - val_loss: 0.0772 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 57/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9702\n","Epoch 00057: val_loss did not improve from 0.07721\n","\n","Epoch 00057: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0774 - accuracy: 0.9702 - val_loss: 0.0774 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 58/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9702\n","Epoch 00058: val_loss improved from 0.07721 to 0.07713, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00058: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0773 - accuracy: 0.9702 - val_loss: 0.0771 - val_accuracy: 0.9702 - lr: 1.4286e-04\n","Epoch 59/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9702\n","Epoch 00059: val_loss improved from 0.07713 to 0.07713, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00059: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0773 - accuracy: 0.9702 - val_loss: 0.0771 - val_accuracy: 0.9702 - lr: 1.4286e-04\n","Epoch 60/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9702\n","Epoch 00060: val_loss did not improve from 0.07713\n","\n","Epoch 00060: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0773 - accuracy: 0.9702 - val_loss: 0.0773 - val_accuracy: 0.9701 - lr: 1.4286e-04\n","Epoch 61/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00061: val_loss did not improve from 0.07713\n","\n","Epoch 00061: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0772 - val_accuracy: 0.9701 - lr: 1.1111e-04\n","Epoch 62/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00062: val_loss improved from 0.07713 to 0.07701, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00062: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 63/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00063: val_loss did not improve from 0.07701\n","\n","Epoch 00063: val_accuracy did not improve from 0.97020\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0771 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 64/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00064: val_loss improved from 0.07701 to 0.07693, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00064: val_accuracy improved from 0.97020 to 0.97024, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 53s 568ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0769 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 65/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00065: val_loss did not improve from 0.07693\n","\n","Epoch 00065: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0771 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 66/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00066: val_loss did not improve from 0.07693\n","\n","Epoch 00066: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0771 - val_accuracy: 0.9701 - lr: 1.1111e-04\n","Epoch 67/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9702\n","Epoch 00067: val_loss did not improve from 0.07693\n","\n","Epoch 00067: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 68/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9703\n","Epoch 00068: val_loss did not improve from 0.07693\n","\n","Epoch 00068: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 69/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9703\n","Epoch 00069: val_loss did not improve from 0.07693\n","\n","Epoch 00069: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0770 - accuracy: 0.9703 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 70/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9703\n","Epoch 00070: val_loss did not improve from 0.07693\n","\n","Epoch 00070: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0769 - accuracy: 0.9703 - val_loss: 0.0771 - val_accuracy: 0.9702 - lr: 1.1111e-04\n","Epoch 71/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9703\n","Epoch 00071: val_loss did not improve from 0.07693\n","\n","Epoch 00071: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0769 - accuracy: 0.9703 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 72/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9703\n","Epoch 00072: val_loss did not improve from 0.07693\n","\n","Epoch 00072: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0769 - accuracy: 0.9703 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 73/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9704\n","Epoch 00073: val_loss improved from 0.07693 to 0.07688, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00073: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0768 - accuracy: 0.9704 - val_loss: 0.0769 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 74/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00074: val_loss did not improve from 0.07688\n","\n","Epoch 00074: val_accuracy did not improve from 0.97024\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0770 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 75/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00075: val_loss improved from 0.07688 to 0.07679, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00075: val_accuracy improved from 0.97024 to 0.97027, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 52s 549ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0768 - val_accuracy: 0.9703 - lr: 9.0909e-05\n","Epoch 76/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703\n","Epoch 00076: val_loss did not improve from 0.07679\n","\n","Epoch 00076: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.0773 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 77/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9704\n","Epoch 00077: val_loss did not improve from 0.07679\n","\n","Epoch 00077: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0768 - accuracy: 0.9704 - val_loss: 0.0769 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 78/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9704\n","Epoch 00078: val_loss did not improve from 0.07679\n","\n","Epoch 00078: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0768 - accuracy: 0.9704 - val_loss: 0.0769 - val_accuracy: 0.9701 - lr: 9.0909e-05\n","Epoch 79/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9704\n","Epoch 00079: val_loss improved from 0.07679 to 0.07678, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00079: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0768 - accuracy: 0.9704 - val_loss: 0.0768 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 80/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9704\n","Epoch 00080: val_loss improved from 0.07678 to 0.07671, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00080: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0767 - accuracy: 0.9704 - val_loss: 0.0767 - val_accuracy: 0.9702 - lr: 9.0909e-05\n","Epoch 81/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9704\n","Epoch 00081: val_loss did not improve from 0.07671\n","\n","Epoch 00081: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0767 - accuracy: 0.9704 - val_loss: 0.0767 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 82/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9703\n","Epoch 00082: val_loss did not improve from 0.07671\n","\n","Epoch 00082: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0767 - accuracy: 0.9703 - val_loss: 0.0767 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 83/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9704\n","Epoch 00083: val_loss did not improve from 0.07671\n","\n","Epoch 00083: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.0769 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 84/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9704\n","Epoch 00084: val_loss did not improve from 0.07671\n","\n","Epoch 00084: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.0769 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 85/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9704\n","Epoch 00085: val_loss did not improve from 0.07671\n","\n","Epoch 00085: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.0768 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 86/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9704\n","Epoch 00086: val_loss did not improve from 0.07671\n","\n","Epoch 00086: val_accuracy did not improve from 0.97027\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.0768 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 87/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9704\n","Epoch 00087: val_loss improved from 0.07671 to 0.07669, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00087: val_accuracy improved from 0.97027 to 0.97030, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 51s 547ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.0767 - val_accuracy: 0.9703 - lr: 7.6923e-05\n","Epoch 88/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9704\n","Epoch 00088: val_loss did not improve from 0.07669\n","\n","Epoch 00088: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 52s 558ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.0767 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 89/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9704\n","Epoch 00089: val_loss did not improve from 0.07669\n","\n","Epoch 00089: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.0769 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 90/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9704\n","Epoch 00090: val_loss improved from 0.07669 to 0.07668, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00090: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.0767 - val_accuracy: 0.9702 - lr: 7.6923e-05\n","Epoch 91/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00091: val_loss improved from 0.07668 to 0.07656, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00091: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 92/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00092: val_loss improved from 0.07656 to 0.07655, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00092: val_accuracy improved from 0.97030 to 0.97030, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_score.h5\n","94/94 [==============================] - 52s 548ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 93/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00093: val_loss improved from 0.07655 to 0.07655, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00093: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 94/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00094: val_loss did not improve from 0.07655\n","\n","Epoch 00094: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 95/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00095: val_loss did not improve from 0.07655\n","\n","Epoch 00095: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9702 - lr: 1.0000e-05\n","Epoch 96/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00096: val_loss did not improve from 0.07655\n","\n","Epoch 00096: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 97/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00097: val_loss did not improve from 0.07655\n","\n","Epoch 00097: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 98/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00098: val_loss improved from 0.07655 to 0.07655, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00098: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0765 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 99/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00099: val_loss did not improve from 0.07655\n","\n","Epoch 00099: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 100/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00100: val_loss did not improve from 0.07655\n","\n","Epoch 00100: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 101/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00101: val_loss did not improve from 0.07655\n","\n","Epoch 00101: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 102/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00102: val_loss did not improve from 0.07655\n","\n","Epoch 00102: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 103/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00103: val_loss did not improve from 0.07655\n","\n","Epoch 00103: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0765 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 104/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00104: val_loss improved from 0.07655 to 0.07653, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold2_best_loss.h5\n","\n","Epoch 00104: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 51s 548ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0765 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 105/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00105: val_loss did not improve from 0.07653\n","\n","Epoch 00105: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 106/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00106: val_loss did not improve from 0.07653\n","\n","Epoch 00106: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0765 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 107/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9705\n","Epoch 00107: val_loss did not improve from 0.07653\n","\n","Epoch 00107: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0762 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 108/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9705\n","Epoch 00108: val_loss did not improve from 0.07653\n","\n","Epoch 00108: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0762 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 109/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n","Epoch 00109: val_loss did not improve from 0.07653\n","\n","Epoch 00109: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9703 - lr: 1.0000e-05\n","Epoch 110/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9705\n","Epoch 00110: val_loss did not improve from 0.07653\n","\n","Epoch 00110: val_accuracy did not improve from 0.97030\n","94/94 [==============================] - 50s 536ms/step - loss: 0.0762 - accuracy: 0.9705 - val_loss: 0.0766 - val_accuracy: 0.9702 - lr: 1.0000e-05\n"],"name":"stdout"},{"output_type":"stream","text":["Training fold 2 completed. macro f1 score : 0.94162\n","[##### Running Fold: 2 #####] done in 5666 s\n","[##### Running Fold: 3 #####] start\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23a7fe9275394ba1953c8785a735310a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3721f923128498fae619fa1930c099d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch 1/110\n","94/94 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.8104\n","Epoch 00001: val_loss improved from inf to 0.15157, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.95613, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 59s 625ms/step - loss: 0.6047 - accuracy: 0.8104 - val_loss: 0.1516 - val_accuracy: 0.9561 - lr: 0.0010\n","Epoch 2/110\n","94/94 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9627\n","Epoch 00002: val_loss improved from 0.15157 to 0.09936, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00002: val_accuracy improved from 0.95613 to 0.96522, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 52s 558ms/step - loss: 0.1144 - accuracy: 0.9627 - val_loss: 0.0994 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 3/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9656\n","Epoch 00003: val_loss improved from 0.09936 to 0.09148, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00003: val_accuracy improved from 0.96522 to 0.96650, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 52s 549ms/step - loss: 0.0961 - accuracy: 0.9656 - val_loss: 0.0915 - val_accuracy: 0.9665 - lr: 0.0010\n","Epoch 4/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9663\n","Epoch 00004: val_loss improved from 0.09148 to 0.08824, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00004: val_accuracy improved from 0.96650 to 0.96709, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 546ms/step - loss: 0.0919 - accuracy: 0.9663 - val_loss: 0.0882 - val_accuracy: 0.9671 - lr: 0.0010\n","Epoch 5/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9664\n","Epoch 00005: val_loss did not improve from 0.08824\n","\n","Epoch 00005: val_accuracy did not improve from 0.96709\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0910 - accuracy: 0.9664 - val_loss: 0.0884 - val_accuracy: 0.9667 - lr: 0.0010\n","Epoch 6/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9661\n","Epoch 00006: val_loss improved from 0.08824 to 0.08620, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00006: val_accuracy improved from 0.96709 to 0.96757, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 547ms/step - loss: 0.0913 - accuracy: 0.9661 - val_loss: 0.0862 - val_accuracy: 0.9676 - lr: 0.0010\n","Epoch 7/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9651\n","Epoch 00007: val_loss did not improve from 0.08620\n","\n","Epoch 00007: val_accuracy did not improve from 0.96757\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0939 - accuracy: 0.9651 - val_loss: 0.0973 - val_accuracy: 0.9639 - lr: 0.0010\n","Epoch 8/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9663\n","Epoch 00008: val_loss improved from 0.08620 to 0.08576, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00008: val_accuracy did not improve from 0.96757\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0903 - accuracy: 0.9663 - val_loss: 0.0858 - val_accuracy: 0.9675 - lr: 0.0010\n","Epoch 9/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9670\n","Epoch 00009: val_loss improved from 0.08576 to 0.08485, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00009: val_accuracy improved from 0.96757 to 0.96764, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0877 - accuracy: 0.9670 - val_loss: 0.0848 - val_accuracy: 0.9676 - lr: 0.0010\n","Epoch 10/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9672\n","Epoch 00010: val_loss did not improve from 0.08485\n","\n","Epoch 00010: val_accuracy improved from 0.96764 to 0.96767, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0872 - accuracy: 0.9672 - val_loss: 0.0853 - val_accuracy: 0.9677 - lr: 0.0010\n","Epoch 11/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9672\n","Epoch 00011: val_loss improved from 0.08485 to 0.08434, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00011: val_accuracy improved from 0.96767 to 0.96781, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0871 - accuracy: 0.9672 - val_loss: 0.0843 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 12/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9670\n","Epoch 00012: val_loss improved from 0.08434 to 0.08425, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00012: val_accuracy improved from 0.96781 to 0.96786, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0874 - accuracy: 0.9670 - val_loss: 0.0842 - val_accuracy: 0.9679 - lr: 0.0010\n","Epoch 13/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9674\n","Epoch 00013: val_loss improved from 0.08425 to 0.08423, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00013: val_accuracy did not improve from 0.96786\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0864 - accuracy: 0.9674 - val_loss: 0.0842 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 14/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9675\n","Epoch 00014: val_loss did not improve from 0.08423\n","\n","Epoch 00014: val_accuracy did not improve from 0.96786\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0860 - accuracy: 0.9675 - val_loss: 0.0872 - val_accuracy: 0.9667 - lr: 0.0010\n","Epoch 15/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9670\n","Epoch 00015: val_loss did not improve from 0.08423\n","\n","Epoch 00015: val_accuracy did not improve from 0.96786\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0870 - accuracy: 0.9670 - val_loss: 0.0970 - val_accuracy: 0.9626 - lr: 0.0010\n","Epoch 16/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9670\n","Epoch 00016: val_loss improved from 0.08423 to 0.08386, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00016: val_accuracy improved from 0.96786 to 0.96802, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0872 - accuracy: 0.9670 - val_loss: 0.0839 - val_accuracy: 0.9680 - lr: 0.0010\n","Epoch 17/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9675\n","Epoch 00017: val_loss did not improve from 0.08386\n","\n","Epoch 00017: val_accuracy did not improve from 0.96802\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0855 - accuracy: 0.9675 - val_loss: 0.0839 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 18/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9677\n","Epoch 00018: val_loss improved from 0.08386 to 0.08216, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00018: val_accuracy improved from 0.96802 to 0.96847, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0848 - accuracy: 0.9677 - val_loss: 0.0822 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 19/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9678\n","Epoch 00019: val_loss did not improve from 0.08216\n","\n","Epoch 00019: val_accuracy did not improve from 0.96847\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0850 - accuracy: 0.9678 - val_loss: 0.0828 - val_accuracy: 0.9682 - lr: 0.0010\n","Epoch 20/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9677\n","Epoch 00020: val_loss did not improve from 0.08216\n","\n","Epoch 00020: val_accuracy improved from 0.96847 to 0.96850, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0850 - accuracy: 0.9677 - val_loss: 0.0823 - val_accuracy: 0.9685 - lr: 0.0010\n","Epoch 21/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9671\n","Epoch 00021: val_loss did not improve from 0.08216\n","\n","Epoch 00021: val_accuracy did not improve from 0.96850\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0867 - accuracy: 0.9671 - val_loss: 0.0844 - val_accuracy: 0.9677 - lr: 0.0010\n","Epoch 22/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9680\n","Epoch 00022: val_loss improved from 0.08216 to 0.08163, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00022: val_accuracy improved from 0.96850 to 0.96867, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 546ms/step - loss: 0.0839 - accuracy: 0.9680 - val_loss: 0.0816 - val_accuracy: 0.9687 - lr: 0.0010\n","Epoch 23/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9682\n","Epoch 00023: val_loss improved from 0.08163 to 0.08125, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00023: val_accuracy improved from 0.96867 to 0.96869, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0832 - accuracy: 0.9682 - val_loss: 0.0812 - val_accuracy: 0.9687 - lr: 0.0010\n","Epoch 24/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9683\n","Epoch 00024: val_loss improved from 0.08125 to 0.08048, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00024: val_accuracy improved from 0.96869 to 0.96890, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 53s 567ms/step - loss: 0.0828 - accuracy: 0.9683 - val_loss: 0.0805 - val_accuracy: 0.9689 - lr: 0.0010\n","Epoch 25/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9683\n","Epoch 00025: val_loss did not improve from 0.08048\n","\n","Epoch 00025: val_accuracy did not improve from 0.96890\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0828 - accuracy: 0.9683 - val_loss: 0.0807 - val_accuracy: 0.9688 - lr: 0.0010\n","Epoch 26/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9683\n","Epoch 00026: val_loss improved from 0.08048 to 0.08038, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00026: val_accuracy did not improve from 0.96890\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0829 - accuracy: 0.9683 - val_loss: 0.0804 - val_accuracy: 0.9689 - lr: 0.0010\n","Epoch 27/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9668\n","Epoch 00027: val_loss did not improve from 0.08038\n","\n","Epoch 00027: val_accuracy did not improve from 0.96890\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0871 - accuracy: 0.9668 - val_loss: 0.0881 - val_accuracy: 0.9666 - lr: 0.0010\n","Epoch 28/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9676\n","Epoch 00028: val_loss did not improve from 0.08038\n","\n","Epoch 00028: val_accuracy did not improve from 0.96890\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0850 - accuracy: 0.9676 - val_loss: 0.0813 - val_accuracy: 0.9687 - lr: 0.0010\n","Epoch 29/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9684\n","Epoch 00029: val_loss did not improve from 0.08038\n","\n","Epoch 00029: val_accuracy did not improve from 0.96890\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0826 - accuracy: 0.9684 - val_loss: 0.0822 - val_accuracy: 0.9682 - lr: 0.0010\n","Epoch 30/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9681\n","Epoch 00030: val_loss did not improve from 0.08038\n","\n","Epoch 00030: val_accuracy did not improve from 0.96890\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0834 - accuracy: 0.9681 - val_loss: 0.0823 - val_accuracy: 0.9682 - lr: 0.0010\n","Epoch 31/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9687\n","Epoch 00031: val_loss improved from 0.08038 to 0.07993, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00031: val_accuracy improved from 0.96890 to 0.96901, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0814 - accuracy: 0.9687 - val_loss: 0.0799 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 32/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9688\n","Epoch 00032: val_loss improved from 0.07993 to 0.07976, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00032: val_accuracy improved from 0.96901 to 0.96907, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.0798 - val_accuracy: 0.9691 - lr: 3.3333e-04\n","Epoch 33/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9688\n","Epoch 00033: val_loss did not improve from 0.07976\n","\n","Epoch 00033: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.0799 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 34/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9688\n","Epoch 00034: val_loss did not improve from 0.07976\n","\n","Epoch 00034: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0810 - accuracy: 0.9688 - val_loss: 0.0798 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 35/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9688\n","Epoch 00035: val_loss improved from 0.07976 to 0.07973, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00035: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0809 - accuracy: 0.9688 - val_loss: 0.0797 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 36/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9688\n","Epoch 00036: val_loss improved from 0.07973 to 0.07968, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00036: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0810 - accuracy: 0.9688 - val_loss: 0.0797 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 37/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9689\n","Epoch 00037: val_loss did not improve from 0.07968\n","\n","Epoch 00037: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0807 - accuracy: 0.9689 - val_loss: 0.0798 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 38/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9688\n","Epoch 00038: val_loss improved from 0.07968 to 0.07945, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00038: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0808 - accuracy: 0.9688 - val_loss: 0.0795 - val_accuracy: 0.9691 - lr: 3.3333e-04\n","Epoch 39/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9689\n","Epoch 00039: val_loss did not improve from 0.07945\n","\n","Epoch 00039: val_accuracy did not improve from 0.96907\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0807 - accuracy: 0.9689 - val_loss: 0.0799 - val_accuracy: 0.9690 - lr: 3.3333e-04\n","Epoch 40/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9689\n","Epoch 00040: val_loss did not improve from 0.07945\n","\n","Epoch 00040: val_accuracy improved from 0.96907 to 0.96908, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0806 - accuracy: 0.9689 - val_loss: 0.0795 - val_accuracy: 0.9691 - lr: 3.3333e-04\n","Epoch 41/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9690\n","Epoch 00041: val_loss did not improve from 0.07945\n","\n","Epoch 00041: val_accuracy improved from 0.96908 to 0.96908, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0804 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9691 - lr: 2.0000e-04\n","Epoch 42/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9690\n","Epoch 00042: val_loss improved from 0.07945 to 0.07938, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00042: val_accuracy improved from 0.96908 to 0.96912, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0803 - accuracy: 0.9690 - val_loss: 0.0794 - val_accuracy: 0.9691 - lr: 2.0000e-04\n","Epoch 43/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9690\n","Epoch 00043: val_loss did not improve from 0.07938\n","\n","Epoch 00043: val_accuracy did not improve from 0.96912\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0804 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9691 - lr: 2.0000e-04\n","Epoch 44/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00044: val_loss improved from 0.07938 to 0.07921, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00044: val_accuracy improved from 0.96912 to 0.96916, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0792 - val_accuracy: 0.9692 - lr: 2.0000e-04\n","Epoch 45/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00045: val_loss did not improve from 0.07921\n","\n","Epoch 00045: val_accuracy did not improve from 0.96916\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0792 - val_accuracy: 0.9691 - lr: 2.0000e-04\n","Epoch 46/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00046: val_loss improved from 0.07921 to 0.07910, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00046: val_accuracy improved from 0.96916 to 0.96920, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 546ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0791 - val_accuracy: 0.9692 - lr: 2.0000e-04\n","Epoch 47/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00047: val_loss did not improve from 0.07910\n","\n","Epoch 00047: val_accuracy did not improve from 0.96920\n","94/94 [==============================] - 53s 562ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0793 - val_accuracy: 0.9691 - lr: 2.0000e-04\n","Epoch 48/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00048: val_loss did not improve from 0.07910\n","\n","Epoch 00048: val_accuracy did not improve from 0.96920\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0796 - val_accuracy: 0.9691 - lr: 2.0000e-04\n","Epoch 49/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9690\n","Epoch 00049: val_loss did not improve from 0.07910\n","\n","Epoch 00049: val_accuracy did not improve from 0.96920\n","94/94 [==============================] - 51s 537ms/step - loss: 0.0802 - accuracy: 0.9690 - val_loss: 0.0796 - val_accuracy: 0.9690 - lr: 2.0000e-04\n","Epoch 50/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9690\n","Epoch 00050: val_loss improved from 0.07910 to 0.07904, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00050: val_accuracy improved from 0.96920 to 0.96922, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 547ms/step - loss: 0.0801 - accuracy: 0.9690 - val_loss: 0.0790 - val_accuracy: 0.9692 - lr: 2.0000e-04\n","Epoch 51/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9691\n","Epoch 00051: val_loss improved from 0.07904 to 0.07898, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00051: val_accuracy did not improve from 0.96922\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0799 - accuracy: 0.9691 - val_loss: 0.0790 - val_accuracy: 0.9692 - lr: 1.4286e-04\n","Epoch 52/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9691\n","Epoch 00052: val_loss did not improve from 0.07898\n","\n","Epoch 00052: val_accuracy did not improve from 0.96922\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0799 - accuracy: 0.9691 - val_loss: 0.0790 - val_accuracy: 0.9692 - lr: 1.4286e-04\n","Epoch 53/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9691\n","Epoch 00053: val_loss did not improve from 0.07898\n","\n","Epoch 00053: val_accuracy improved from 0.96922 to 0.96925, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0799 - accuracy: 0.9691 - val_loss: 0.0791 - val_accuracy: 0.9693 - lr: 1.4286e-04\n","Epoch 54/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9691\n","Epoch 00054: val_loss improved from 0.07898 to 0.07890, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00054: val_accuracy improved from 0.96925 to 0.96926, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 548ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.0789 - val_accuracy: 0.9693 - lr: 1.4286e-04\n","Epoch 55/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9691\n","Epoch 00055: val_loss improved from 0.07890 to 0.07888, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00055: val_accuracy did not improve from 0.96926\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.0789 - val_accuracy: 0.9692 - lr: 1.4286e-04\n","Epoch 56/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9691\n","Epoch 00056: val_loss did not improve from 0.07888\n","\n","Epoch 00056: val_accuracy did not improve from 0.96926\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.0790 - val_accuracy: 0.9692 - lr: 1.4286e-04\n","Epoch 57/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9691\n","Epoch 00057: val_loss did not improve from 0.07888\n","\n","Epoch 00057: val_accuracy did not improve from 0.96926\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0797 - accuracy: 0.9691 - val_loss: 0.0789 - val_accuracy: 0.9692 - lr: 1.4286e-04\n","Epoch 58/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9692\n","Epoch 00058: val_loss improved from 0.07888 to 0.07879, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00058: val_accuracy improved from 0.96926 to 0.96930, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 546ms/step - loss: 0.0797 - accuracy: 0.9692 - val_loss: 0.0788 - val_accuracy: 0.9693 - lr: 1.4286e-04\n","Epoch 59/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9692\n","Epoch 00059: val_loss did not improve from 0.07879\n","\n","Epoch 00059: val_accuracy did not improve from 0.96930\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0797 - accuracy: 0.9692 - val_loss: 0.0792 - val_accuracy: 0.9691 - lr: 1.4286e-04\n","Epoch 60/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9692\n","Epoch 00060: val_loss did not improve from 0.07879\n","\n","Epoch 00060: val_accuracy did not improve from 0.96930\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0797 - accuracy: 0.9692 - val_loss: 0.0788 - val_accuracy: 0.9693 - lr: 1.4286e-04\n","Epoch 61/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9692\n","Epoch 00061: val_loss improved from 0.07879 to 0.07875, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00061: val_accuracy did not improve from 0.96930\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0795 - accuracy: 0.9692 - val_loss: 0.0788 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 62/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9692\n","Epoch 00062: val_loss did not improve from 0.07875\n","\n","Epoch 00062: val_accuracy improved from 0.96930 to 0.96931, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0795 - accuracy: 0.9692 - val_loss: 0.0788 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 63/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00063: val_loss improved from 0.07875 to 0.07874, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00063: val_accuracy improved from 0.96931 to 0.96935, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 52s 548ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0787 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 64/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00064: val_loss improved from 0.07874 to 0.07872, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00064: val_accuracy improved from 0.96935 to 0.96938, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0787 - val_accuracy: 0.9694 - lr: 1.1111e-04\n","Epoch 65/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00065: val_loss improved from 0.07872 to 0.07861, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00065: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0786 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 66/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00066: val_loss improved from 0.07861 to 0.07855, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00066: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 51s 538ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0785 - val_accuracy: 0.9694 - lr: 1.1111e-04\n","Epoch 67/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9693\n","Epoch 00067: val_loss did not improve from 0.07855\n","\n","Epoch 00067: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0788 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 68/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9693\n","Epoch 00068: val_loss did not improve from 0.07855\n","\n","Epoch 00068: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0793 - accuracy: 0.9693 - val_loss: 0.0789 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 69/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9693\n","Epoch 00069: val_loss did not improve from 0.07855\n","\n","Epoch 00069: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 50s 531ms/step - loss: 0.0793 - accuracy: 0.9693 - val_loss: 0.0786 - val_accuracy: 0.9694 - lr: 1.1111e-04\n","Epoch 70/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9693\n","Epoch 00070: val_loss did not improve from 0.07855\n","\n","Epoch 00070: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0793 - accuracy: 0.9693 - val_loss: 0.0787 - val_accuracy: 0.9693 - lr: 1.1111e-04\n","Epoch 71/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9694\n","Epoch 00071: val_loss did not improve from 0.07855\n","\n","Epoch 00071: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 52s 558ms/step - loss: 0.0791 - accuracy: 0.9694 - val_loss: 0.0787 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 72/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9694\n","Epoch 00072: val_loss did not improve from 0.07855\n","\n","Epoch 00072: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0791 - accuracy: 0.9694 - val_loss: 0.0787 - val_accuracy: 0.9693 - lr: 9.0909e-05\n","Epoch 73/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9694\n","Epoch 00073: val_loss did not improve from 0.07855\n","\n","Epoch 00073: val_accuracy did not improve from 0.96938\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0791 - accuracy: 0.9694 - val_loss: 0.0788 - val_accuracy: 0.9693 - lr: 9.0909e-05\n","Epoch 74/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9694\n","Epoch 00074: val_loss improved from 0.07855 to 0.07852, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00074: val_accuracy improved from 0.96938 to 0.96939, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 544ms/step - loss: 0.0792 - accuracy: 0.9694 - val_loss: 0.0785 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 75/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9694\n","Epoch 00075: val_loss did not improve from 0.07852\n","\n","Epoch 00075: val_accuracy did not improve from 0.96939\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0791 - accuracy: 0.9694 - val_loss: 0.0786 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 76/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9694\n","Epoch 00076: val_loss improved from 0.07852 to 0.07845, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00076: val_accuracy improved from 0.96939 to 0.96942, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.0784 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 77/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9694\n","Epoch 00077: val_loss did not improve from 0.07845\n","\n","Epoch 00077: val_accuracy did not improve from 0.96942\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.0787 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 78/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9694\n","Epoch 00078: val_loss did not improve from 0.07845\n","\n","Epoch 00078: val_accuracy did not improve from 0.96942\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.0786 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 79/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9694\n","Epoch 00079: val_loss did not improve from 0.07845\n","\n","Epoch 00079: val_accuracy did not improve from 0.96942\n","94/94 [==============================] - 50s 532ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.0785 - val_accuracy: 0.9694 - lr: 9.0909e-05\n","Epoch 80/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9694\n","Epoch 00080: val_loss did not improve from 0.07845\n","\n","Epoch 00080: val_accuracy did not improve from 0.96942\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.0787 - val_accuracy: 0.9693 - lr: 9.0909e-05\n","Epoch 81/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9695\n","Epoch 00081: val_loss did not improve from 0.07845\n","\n","Epoch 00081: val_accuracy did not improve from 0.96942\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.0786 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 82/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9695\n","Epoch 00082: val_loss did not improve from 0.07845\n","\n","Epoch 00082: val_accuracy improved from 0.96942 to 0.96945, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.0785 - val_accuracy: 0.9695 - lr: 7.6923e-05\n","Epoch 83/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9695\n","Epoch 00083: val_loss did not improve from 0.07845\n","\n","Epoch 00083: val_accuracy did not improve from 0.96945\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.0785 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 84/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9695\n","Epoch 00084: val_loss improved from 0.07845 to 0.07831, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00084: val_accuracy did not improve from 0.96945\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0788 - accuracy: 0.9695 - val_loss: 0.0783 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 85/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9695\n","Epoch 00085: val_loss did not improve from 0.07831\n","\n","Epoch 00085: val_accuracy did not improve from 0.96945\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0788 - accuracy: 0.9695 - val_loss: 0.0784 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 86/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9695\n","Epoch 00086: val_loss did not improve from 0.07831\n","\n","Epoch 00086: val_accuracy did not improve from 0.96945\n","94/94 [==============================] - 50s 530ms/step - loss: 0.0787 - accuracy: 0.9695 - val_loss: 0.0784 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 87/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9695\n","Epoch 00087: val_loss did not improve from 0.07831\n","\n","Epoch 00087: val_accuracy improved from 0.96945 to 0.96950, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0787 - accuracy: 0.9695 - val_loss: 0.0783 - val_accuracy: 0.9695 - lr: 7.6923e-05\n","Epoch 88/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9695\n","Epoch 00088: val_loss did not improve from 0.07831\n","\n","Epoch 00088: val_accuracy did not improve from 0.96950\n","94/94 [==============================] - 50s 535ms/step - loss: 0.0787 - accuracy: 0.9695 - val_loss: 0.0785 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 89/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9696\n","Epoch 00089: val_loss improved from 0.07831 to 0.07825, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00089: val_accuracy did not improve from 0.96950\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0787 - accuracy: 0.9696 - val_loss: 0.0783 - val_accuracy: 0.9695 - lr: 7.6923e-05\n","Epoch 90/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9696\n","Epoch 00090: val_loss did not improve from 0.07825\n","\n","Epoch 00090: val_accuracy did not improve from 0.96950\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0787 - accuracy: 0.9696 - val_loss: 0.0785 - val_accuracy: 0.9694 - lr: 7.6923e-05\n","Epoch 91/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9696\n","Epoch 00091: val_loss improved from 0.07825 to 0.07815, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00091: val_accuracy improved from 0.96950 to 0.96951, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 545ms/step - loss: 0.0785 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 92/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00092: val_loss did not improve from 0.07815\n","\n","Epoch 00092: val_accuracy improved from 0.96951 to 0.96951, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 93/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00093: val_loss improved from 0.07815 to 0.07813, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00093: val_accuracy did not improve from 0.96951\n","94/94 [==============================] - 51s 541ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 94/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00094: val_loss did not improve from 0.07813\n","\n","Epoch 00094: val_accuracy improved from 0.96951 to 0.96952, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 53s 566ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 95/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00095: val_loss did not improve from 0.07813\n","\n","Epoch 00095: val_accuracy did not improve from 0.96952\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 96/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00096: val_loss did not improve from 0.07813\n","\n","Epoch 00096: val_accuracy improved from 0.96952 to 0.96952, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 540ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 97/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00097: val_loss did not improve from 0.07813\n","\n","Epoch 00097: val_accuracy did not improve from 0.96952\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 98/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00098: val_loss did not improve from 0.07813\n","\n","Epoch 00098: val_accuracy did not improve from 0.96952\n","94/94 [==============================] - 50s 533ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 99/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00099: val_loss improved from 0.07813 to 0.07813, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00099: val_accuracy improved from 0.96952 to 0.96952, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 52s 550ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 100/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00100: val_loss did not improve from 0.07813\n","\n","Epoch 00100: val_accuracy improved from 0.96952 to 0.96953, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 101/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00101: val_loss did not improve from 0.07813\n","\n","Epoch 00101: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 102/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9696\n","Epoch 00102: val_loss did not improve from 0.07813\n","\n","Epoch 00102: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0784 - accuracy: 0.9696 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 103/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00103: val_loss did not improve from 0.07813\n","\n","Epoch 00103: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 104/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00104: val_loss did not improve from 0.07813\n","\n","Epoch 00104: val_accuracy improved from 0.96953 to 0.96953, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 543ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 105/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00105: val_loss did not improve from 0.07813\n","\n","Epoch 00105: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 51s 539ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 106/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00106: val_loss did not improve from 0.07813\n","\n","Epoch 00106: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0782 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 107/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00107: val_loss improved from 0.07813 to 0.07810, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_loss.h5\n","\n","Epoch 00107: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 108/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9697\n","Epoch 00108: val_loss did not improve from 0.07810\n","\n","Epoch 00108: val_accuracy improved from 0.96953 to 0.96953, saving model to ./drive/My Drive/Colab Notebooks/Ion/stack1/keras_fold3_best_score.h5\n","94/94 [==============================] - 51s 542ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 109/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9697\n","Epoch 00109: val_loss did not improve from 0.07810\n","\n","Epoch 00109: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 534ms/step - loss: 0.0783 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n","Epoch 110/110\n","94/94 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9697\n","Epoch 00110: val_loss did not improve from 0.07810\n","\n","Epoch 00110: val_accuracy did not improve from 0.96953\n","94/94 [==============================] - 50s 537ms/step - loss: 0.0783 - accuracy: 0.9697 - val_loss: 0.0781 - val_accuracy: 0.9695 - lr: 1.0000e-05\n"],"name":"stdout"},{"output_type":"stream","text":["Training fold 3 completed. macro f1 score : 0.94020\n","[##### Running Fold: 3 #####] done in 5690 s\n","##### CV Score: 0.9410183626324503 #####\n"],"name":"stderr"}]}]}